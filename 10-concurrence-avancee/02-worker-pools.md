üîù Retour au [Sommaire](/SOMMAIRE.md)

# 10-2 : Worker pools

## Introduction

Un **worker pool** (pool de travailleurs) est un pattern de concurrence tr√®s populaire en Go. Il permet de traiter efficacement un grand nombre de t√¢ches en parall√®le en utilisant un nombre fixe de goroutines "travailleuses". C'est l'√©quivalent d'une √©quipe de travailleurs qui se partagent une pile de t√¢ches √† accomplir.

## Pourquoi utiliser un worker pool ?

### Probl√®me sans worker pool

Imaginez que vous devez traiter 10 000 fichiers. Une approche na√Øve serait :

```go
// ‚ùå MAUVAISE APPROCHE : Trop de goroutines !
for i := 0; i < 10000; i++ {
    go func(fileID int) {
        processFile(fileID)
    }(i)
}
```

**Probl√®mes** :
- **10 000 goroutines** cr√©√©es simultan√©ment
- **Surcharge m√©moire** √©norme
- **Contention des ressources** (CPU, r√©seau, disque)
- **Possible crash** du syst√®me

### Solution avec worker pool

```go
// ‚úÖ BONNE APPROCHE : Nombre limit√© de workers
jobs := make(chan int, 100)
numWorkers := 10

// Cr√©er 10 workers seulement
for w := 1; w <= numWorkers; w++ {
    go worker(w, jobs)
}

// Envoyer les t√¢ches
for i := 0; i < 10000; i++ {
    jobs <- i
}
close(jobs)
```

**Avantages** :
- **Nombre contr√¥l√©** de goroutines (10 au lieu de 10 000)
- **Utilisation optimale** des ressources
- **Stabilit√©** du syst√®me
- **Performance** pr√©visible

## Anatomie d'un worker pool

### Composants principaux

1. **Jobs channel** : Canal contenant les t√¢ches √† traiter
2. **Workers** : Goroutines qui traitent les t√¢ches
3. **Results channel** (optionnel) : Canal pour collecter les r√©sultats
4. **Coordination** : M√©canisme pour savoir quand tout est termin√©

### Sch√©ma conceptuel

```
[T√¢ches] ‚Üí [Jobs Channel] ‚Üí [Worker 1] ‚Üí [Results Channel]
                         ‚Üí [Worker 2] ‚Üí [Results Channel]
                         ‚Üí [Worker 3] ‚Üí [Results Channel]
                         ‚Üí [Worker N] ‚Üí [Results Channel]
```

## Exemple de base

### Worker pool simple

```go
package main

import (
    "fmt"
    "sync"
    "time"
)

// Job repr√©sente une t√¢che √† traiter
type Job struct {
    ID   int
    Data string
}

// Result repr√©sente le r√©sultat d'une t√¢che
type Result struct {
    JobID  int
    Output string
    Error  error
}

// Worker function qui traite les jobs
func worker(id int, jobs <-chan Job, results chan<- Result, wg *sync.WaitGroup) {
    defer wg.Done()

    for job := range jobs {
        fmt.Printf("üë∑ Worker %d traite le job %d\n", id, job.ID)

        // Simulation du travail
        time.Sleep(time.Duration(100+job.ID*10) * time.Millisecond)

        // Cr√©er le r√©sultat
        result := Result{
            JobID:  job.ID,
            Output: fmt.Sprintf("Trait√©: %s", job.Data),
            Error:  nil,
        }

        results <- result
        fmt.Printf("‚úÖ Worker %d termin√© job %d\n", id, job.ID)
    }

    fmt.Printf("üèÅ Worker %d s'arr√™te\n", id)
}

func basicWorkerPool() {
    numWorkers := 3
    numJobs := 10

    // Cr√©er les channels
    jobs := make(chan Job, numJobs)
    results := make(chan Result, numJobs)

    // WaitGroup pour attendre tous les workers
    var wg sync.WaitGroup

    // Lancer les workers
    fmt.Printf("üöÄ Lancement de %d workers\n", numWorkers)
    for w := 1; w <= numWorkers; w++ {
        wg.Add(1)
        go worker(w, jobs, results, &wg)
    }

    // Envoyer les jobs
    fmt.Printf("üìã Envoi de %d jobs\n", numJobs)
    for j := 1; j <= numJobs; j++ {
        job := Job{
            ID:   j,
            Data: fmt.Sprintf("donn√©es-%d", j),
        }
        jobs <- job
    }
    close(jobs) // Important : fermer le channel des jobs

    // Collecter les r√©sultats dans une goroutine s√©par√©e
    go func() {
        wg.Wait()
        close(results) // Fermer quand tous les workers sont termin√©s
    }()

    // Lire les r√©sultats
    fmt.Println("üìä Collecte des r√©sultats:")
    for result := range results {
        if result.Error != nil {
            fmt.Printf("‚ùå Erreur job %d: %v\n", result.JobID, result.Error)
        } else {
            fmt.Printf("‚úÖ R√©sultat job %d: %s\n", result.JobID, result.Output)
        }
    }

    fmt.Println("üéâ Tous les jobs sont termin√©s !")
}

func main() {
    basicWorkerPool()
}
```

### Sortie attendue

```
üöÄ Lancement de 3 workers
üìã Envoi de 10 jobs
üë∑ Worker 1 traite le job 1
üë∑ Worker 2 traite le job 2
üë∑ Worker 3 traite le job 3
‚úÖ Worker 1 termin√© job 1
üë∑ Worker 1 traite le job 4
‚úÖ Worker 2 termin√© job 2
üë∑ Worker 2 traite le job 5
...
```

## Worker pool avec gestion d'erreurs

### Version robuste

```go
package main

import (
    "errors"
    "fmt"
    "math/rand"
    "sync"
    "time"
)

type Task struct {
    ID       int
    URL      string
    Retries  int
}

type TaskResult struct {
    TaskID   int
    Success  bool
    Data     string
    Error    error
    Duration time.Duration
}

// Simulation d'une t√¢che qui peut √©chouer
func processTask(task Task) TaskResult {
    start := time.Now()

    // Simulation d'un traitement al√©atoire
    processingTime := time.Duration(rand.Intn(500)) * time.Millisecond
    time.Sleep(processingTime)

    // 20% de chance d'√©chec
    if rand.Float32() < 0.2 {
        return TaskResult{
            TaskID:   task.ID,
            Success:  false,
            Error:    errors.New("traitement √©chou√©"),
            Duration: time.Since(start),
        }
    }

    return TaskResult{
        TaskID:   task.ID,
        Success:  true,
        Data:     fmt.Sprintf("Donn√©es trait√©es pour %s", task.URL),
        Duration: time.Since(start),
    }
}

func robustWorker(id int, tasks <-chan Task, results chan<- TaskResult, wg *sync.WaitGroup) {
    defer wg.Done()

    processed := 0
    for task := range tasks {
        fmt.Printf("üîß Worker %d traite la t√¢che %d (tentative %d)\n",
                  id, task.ID, task.Retries+1)

        result := processTask(task)

        // Si √©chec et des tentatives restantes
        if !result.Success && task.Retries < 2 {
            fmt.Printf("‚ö†Ô∏è Worker %d: √©chec t√¢che %d, nouvelle tentative...\n",
                      id, task.ID)

            // Remettre la t√¢che en queue avec un retry
            retryTask := task
            retryTask.Retries++

            // Utiliser un d√©lai avant retry
            go func() {
                time.Sleep(100 * time.Millisecond)
                tasks <- retryTask
            }()
        } else {
            results <- result
            processed++
        }
    }

    fmt.Printf("üèÅ Worker %d termin√© (%d t√¢ches trait√©es)\n", id, processed)
}

func robustWorkerPool() {
    numWorkers := 4
    numTasks := 15

    tasks := make(chan Task, numTasks*2) // Buffer plus large pour les retries
    results := make(chan TaskResult, numTasks)

    var wg sync.WaitGroup

    // Lancer les workers
    for w := 1; w <= numWorkers; w++ {
        wg.Add(1)
        go robustWorker(w, tasks, results, &wg)
    }

    // Envoyer les t√¢ches initiales
    for i := 1; i <= numTasks; i++ {
        task := Task{
            ID:      i,
            URL:     fmt.Sprintf("https://api.example.com/data/%d", i),
            Retries: 0,
        }
        tasks <- task
    }

    // Fermer et collecter les r√©sultats
    go func() {
        wg.Wait()
        close(results)
    }()

    // Statistiques
    var successful, failed int
    var totalDuration time.Duration

    fmt.Println("üìä R√©sultats:")
    for result := range results {
        totalDuration += result.Duration

        if result.Success {
            successful++
            fmt.Printf("‚úÖ T√¢che %d r√©ussie en %v\n",
                      result.TaskID, result.Duration)
        } else {
            failed++
            fmt.Printf("‚ùå T√¢che %d √©chou√©e: %v\n",
                      result.TaskID, result.Error)
        }
    }

    fmt.Printf("\nüìà Statistiques finales:\n")
    fmt.Printf("   ‚úÖ R√©ussies: %d\n", successful)
    fmt.Printf("   ‚ùå √âchou√©es: %d\n", failed)
    fmt.Printf("   ‚è±Ô∏è Temps moyen: %v\n", totalDuration/time.Duration(successful+failed))

    close(tasks)
}

func main() {
    rand.Seed(time.Now().UnixNano())
    robustWorkerPool()
}
```

## Worker pool configurable

### Version flexible et r√©utilisable

```go
package main

import (
    "context"
    "fmt"
    "sync"
    "time"
)

// WorkerPool repr√©sente un pool de workers configurable
type WorkerPool struct {
    workerCount int
    jobQueue    chan Job
    resultQueue chan Result
    wg          sync.WaitGroup
    ctx         context.Context
    cancel      context.CancelFunc
}

// NewWorkerPool cr√©e un nouveau worker pool
func NewWorkerPool(workerCount, queueSize int) *WorkerPool {
    ctx, cancel := context.WithCancel(context.Background())

    return &WorkerPool{
        workerCount: workerCount,
        jobQueue:    make(chan Job, queueSize),
        resultQueue: make(chan Result, queueSize),
        ctx:         ctx,
        cancel:      cancel,
    }
}

// Start d√©marre tous les workers
func (wp *WorkerPool) Start() {
    for i := 1; i <= wp.workerCount; i++ {
        wp.wg.Add(1)
        go wp.worker(i)
    }

    fmt.Printf("üöÄ Worker pool d√©marr√© avec %d workers\n", wp.workerCount)
}

// Stop arr√™te proprement le worker pool
func (wp *WorkerPool) Stop() {
    close(wp.jobQueue)
    wp.wg.Wait()
    close(wp.resultQueue)
    wp.cancel()
    fmt.Println("üõë Worker pool arr√™t√©")
}

// SubmitJob soumet un job au pool
func (wp *WorkerPool) SubmitJob(job Job) {
    select {
    case wp.jobQueue <- job:
        // Job soumis avec succ√®s
    case <-wp.ctx.Done():
        // Pool ferm√©
        fmt.Printf("‚ö†Ô∏è Pool ferm√©, job %d rejet√©\n", job.ID)
    }
}

// GetResults retourne le canal des r√©sultats
func (wp *WorkerPool) GetResults() <-chan Result {
    return wp.resultQueue
}

// worker est la fonction ex√©cut√©e par chaque worker
func (wp *WorkerPool) worker(id int) {
    defer wp.wg.Done()

    jobsProcessed := 0

    for {
        select {
        case job, ok := <-wp.jobQueue:
            if !ok {
                fmt.Printf("üèÅ Worker %d termin√© (%d jobs trait√©s)\n",
                          id, jobsProcessed)
                return
            }

            // Traiter le job
            result := wp.processJob(id, job)

            // Envoyer le r√©sultat
            select {
            case wp.resultQueue <- result:
                jobsProcessed++
            case <-wp.ctx.Done():
                return
            }

        case <-wp.ctx.Done():
            fmt.Printf("üõë Worker %d arr√™t√© par contexte\n", id)
            return
        }
    }
}

// processJob traite un job individuel
func (wp *WorkerPool) processJob(workerID int, job Job) Result {
    fmt.Printf("‚öôÔ∏è Worker %d traite job %d\n", workerID, job.ID)

    start := time.Now()

    // Simulation du travail
    time.Sleep(time.Duration(job.ID*50) * time.Millisecond)

    return Result{
        JobID:  job.ID,
        Output: fmt.Sprintf("Job %d trait√© par worker %d", job.ID, workerID),
        Error:  nil,
    }
}

// Exemple d'utilisation
func configurableWorkerPoolExample() {
    // Cr√©er un pool avec 3 workers et une queue de 10
    pool := NewWorkerPool(3, 10)

    // D√©marrer le pool
    pool.Start()

    // Soumettre des jobs
    numJobs := 8
    fmt.Printf("üìã Soumission de %d jobs\n", numJobs)

    for i := 1; i <= numJobs; i++ {
        job := Job{
            ID:   i,
            Data: fmt.Sprintf("Donn√©es job %d", i),
        }
        pool.SubmitJob(job)
    }

    // Collecter les r√©sultats
    go func() {
        for result := range pool.GetResults() {
            fmt.Printf("üìä R√©sultat: %s\n", result.Output)
        }
    }()

    // Attendre un peu puis arr√™ter
    time.Sleep(2 * time.Second)
    pool.Stop()

    // Laisser du temps pour afficher les derniers r√©sultats
    time.Sleep(500 * time.Millisecond)
}

func main() {
    configurableWorkerPoolExample()
}
```

## Patterns avanc√©s

### 1. Worker pool avec priorit√©s

```go
type PriorityJob struct {
    Job
    Priority int // Plus √©lev√© = plus prioritaire
}

func priorityWorkerPool() {
    // Utiliser plusieurs channels pour diff√©rentes priorit√©s
    highPriority := make(chan Job, 50)
    normalPriority := make(chan Job, 100)
    lowPriority := make(chan Job, 200)

    // Worker qui traite les priorit√©s
    go func() {
        for {
            select {
            case job := <-highPriority:
                processJob(job)
            case job := <-normalPriority:
                processJob(job)
            case job := <-lowPriority:
                processJob(job)
            }
        }
    }()
}
```

### 2. Worker pool avec limitation de d√©bit

```go
func rateLimitedWorkerPool() {
    rateLimiter := time.NewTicker(100 * time.Millisecond) // Max 10 req/sec
    defer rateLimiter.Stop()

    jobs := make(chan Job, 100)

    go func() {
        for job := range jobs {
            <-rateLimiter.C // Attendre le rate limiter
            processJob(job)
        }
    }()
}
```

### 3. Worker pool dynamique

```go
type DynamicWorkerPool struct {
    minWorkers    int
    maxWorkers    int
    currentWorkers int
    jobQueue      chan Job
    workersWG     sync.WaitGroup
    mu            sync.Mutex
}

func (dwp *DynamicWorkerPool) scaleUp() {
    dwp.mu.Lock()
    defer dwp.mu.Unlock()

    if dwp.currentWorkers < dwp.maxWorkers {
        dwp.currentWorkers++
        dwp.workersWG.Add(1)
        go dwp.worker(dwp.currentWorkers)
        fmt.Printf("üìà Nouveau worker ajout√© (total: %d)\n", dwp.currentWorkers)
    }
}

func (dwp *DynamicWorkerPool) monitor() {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        queueLength := len(dwp.jobQueue)

        // Scale up si la queue est pleine √† 80%
        if queueLength > cap(dwp.jobQueue)*8/10 {
            dwp.scaleUp()
        }

        fmt.Printf("üìä Queue: %d/%d, Workers: %d\n",
                  queueLength, cap(dwp.jobQueue), dwp.currentWorkers)
    }
}
```

## Cas d'usage r√©els

### 1. Traitement d'images

```go
func imageProcessingPool() {
    type ImageJob struct {
        InputPath  string
        OutputPath string
        Width      int
        Height     int
    }

    jobs := make(chan ImageJob, 100)

    // Workers sp√©cialis√©s dans le traitement d'images
    for i := 0; i < 4; i++ {
        go func(workerID int) {
            for job := range jobs {
                fmt.Printf("üñºÔ∏è Worker %d redimensionne %s\n",
                          workerID, job.InputPath)

                // Simulation du redimensionnement
                time.Sleep(200 * time.Millisecond)

                fmt.Printf("‚úÖ Image sauv√©e: %s (%dx%d)\n",
                          job.OutputPath, job.Width, job.Height)
            }
        }(i)
    }
}
```

### 2. Crawling web

```go
func webCrawlerPool() {
    type CrawlJob struct {
        URL   string
        Depth int
    }

    jobs := make(chan CrawlJob, 1000)
    results := make(chan []string, 1000)

    // Workers pour crawler
    for i := 0; i < 10; i++ {
        go func(workerID int) {
            for job := range jobs {
                fmt.Printf("üï∑Ô∏è Worker %d crawle %s\n", workerID, job.URL)

                // Simulation du crawling
                time.Sleep(500 * time.Millisecond)

                // R√©sultats simul√©s
                links := []string{
                    job.URL + "/page1",
                    job.URL + "/page2",
                    job.URL + "/page3",
                }

                results <- links
            }
        }(i)
    }
}
```

## Bonnes pratiques

### ‚úÖ √Ä faire

1. **Taille appropri√©e** : Choisir le bon nombre de workers (g√©n√©ralement = nombre de CPU cores)
2. **Buffer des channels** : Utiliser des channels bufferis√©s pour √©viter les blocages
3. **Fermeture propre** : Toujours fermer les channels et attendre les workers
4. **Gestion d'erreurs** : Inclure une gestion robuste des erreurs
5. **Monitoring** : Ajouter des m√©triques et du logging

### ‚ùå √Ä √©viter

1. **Trop de workers** : Ne pas cr√©er plus de workers que n√©cessaire
2. **Channels non ferm√©s** : Peut causer des fuites de goroutines
3. **Pas de timeout** : Toujours avoir un m√©canisme d'arr√™t
4. **Ignorer les erreurs** : G√©rer tous les cas d'erreur possibles

## Exercices pratiques

### Exercice 1 : Calculateur de nombres premiers

Cr√©ez un worker pool qui trouve tous les nombres premiers entre 1 et 10000.

```go
func primeWorkerPool() {
    // Votre impl√©mentation ici
    // Indices :
    // - Chaque job = un nombre √† tester
    // - R√©sultat = nombre + bool (est premier)
    // - 4-6 workers recommand√©s
}
```

### Exercice 2 : Simulateur de requ√™tes HTTP

Cr√©ez un worker pool qui simule des appels API avec gestion d'erreurs et retry.

```go
func httpSimulatorPool() {
    // Votre impl√©mentation ici
    // Indices :
    // - Simuler des latences variables
    // - 20% de chance d'erreur
    // - 3 tentatives maximum
    // - Collecter les statistiques
}
```

## R√©sum√©

Les worker pools sont un pattern essentiel en Go pour :

- **Contr√¥ler** le nombre de goroutines
- **Optimiser** l'utilisation des ressources
- **Traiter** efficacement de gros volumes
- **Maintenir** la stabilit√© du syst√®me

**Pattern de base** :
1. Cr√©er des channels pour jobs et r√©sultats
2. Lancer un nombre fixe de workers
3. Distribuer les t√¢ches via le channel jobs
4. Collecter les r√©sultats
5. Fermer proprement le syst√®me

La ma√Ætrise des worker pools vous permettra de construire des applications Go performantes et scalables !

‚è≠Ô∏è

# Solutions des exercices pratiques - Worker Pools

## Exercice 1 : Calculateur de nombres premiers

### Solution compl√®te

```go
package main

import (
    "fmt"
    "math"
    "sync"
    "time"
)

// PrimeJob repr√©sente un nombre √† tester
type PrimeJob struct {
    Number int
}

// PrimeResult repr√©sente le r√©sultat du test
type PrimeResult struct {
    Number  int
    IsPrime bool
    Elapsed time.Duration
}

// isPrime v√©rifie si un nombre est premier
func isPrime(n int) bool {
    if n < 2 {
        return false
    }
    if n == 2 {
        return true
    }
    if n%2 == 0 {
        return false
    }

    // V√©rifier les diviseurs impairs jusqu'√† ‚àön
    sqrt := int(math.Sqrt(float64(n)))
    for i := 3; i <= sqrt; i += 2 {
        if n%i == 0 {
            return false
        }
    }
    return true
}

// primeWorker traite les jobs de calcul de nombres premiers
func primeWorker(id int, jobs <-chan PrimeJob, results chan<- PrimeResult, wg *sync.WaitGroup) {
    defer wg.Done()

    processed := 0
    for job := range jobs {
        start := time.Now()

        // Tester si le nombre est premier
        prime := isPrime(job.Number)
        elapsed := time.Since(start)

        // Cr√©er le r√©sultat
        result := PrimeResult{
            Number:  job.Number,
            IsPrime: prime,
            Elapsed: elapsed,
        }

        results <- result
        processed++

        // Log pour les nombres premiers trouv√©s
        if prime {
            fmt.Printf("üî¢ Worker %d: %d est PREMIER (trait√© en %v)\n",
                      id, job.Number, elapsed)
        }
    }

    fmt.Printf("üèÅ Worker %d termin√© (%d nombres test√©s)\n", id, processed)
}

func primeWorkerPool() {
    const (
        numWorkers = 6
        maxNumber  = 10000
    )

    // Cr√©er les channels
    jobs := make(chan PrimeJob, 100)
    results := make(chan PrimeResult, 100)

    var wg sync.WaitGroup

    // D√©marrer les workers
    fmt.Printf("üöÄ D√©marrage de %d workers pour trouver les nombres premiers jusqu'√† %d\n",
              numWorkers, maxNumber)

    startTime := time.Now()

    for w := 1; w <= numWorkers; w++ {
        wg.Add(1)
        go primeWorker(w, jobs, results, &wg)
    }

    // Envoyer tous les jobs
    go func() {
        for i := 1; i <= maxNumber; i++ {
            jobs <- PrimeJob{Number: i}
        }
        close(jobs)
    }()

    // Collecter les r√©sultats dans une goroutine s√©par√©e
    go func() {
        wg.Wait()
        close(results)
    }()

    // Analyser les r√©sultats
    var primes []int
    var totalTests int
    var totalTime time.Duration
    var slowestTest PrimeResult

    fmt.Println("üìä Collecte des r√©sultats...")

    for result := range results {
        totalTests++
        totalTime += result.Elapsed

        if result.IsPrime {
            primes = append(primes, result.Number)
        }

        // Suivre le test le plus lent
        if result.Elapsed > slowestTest.Elapsed {
            slowestTest = result
        }
    }

    totalElapsed := time.Since(startTime)

    // Afficher les statistiques
    fmt.Printf("\nüéâ Calcul termin√© en %v\n", totalElapsed)
    fmt.Printf("üìà Statistiques:\n")
    fmt.Printf("   üî¢ Nombres test√©s: %d\n", totalTests)
    fmt.Printf("   ‚ú® Nombres premiers trouv√©s: %d\n", len(primes))
    fmt.Printf("   ‚è±Ô∏è Temps moyen par test: %v\n", totalTime/time.Duration(totalTests))
    fmt.Printf("   üêå Test le plus lent: %d (%v)\n", slowestTest.Number, slowestTest.Elapsed)
    fmt.Printf("   ‚ö° Tests par seconde: %.0f\n", float64(totalTests)/totalElapsed.Seconds())

    // Afficher quelques nombres premiers
    fmt.Printf("\nüî• Premiers nombres premiers trouv√©s: ")
    for i, prime := range primes {
        if i >= 20 { // Limiter l'affichage
            fmt.Printf("... (et %d autres)", len(primes)-20)
            break
        }
        fmt.Printf("%d ", prime)
    }
    fmt.Println()

    // Afficher les plus grands nombres premiers
    if len(primes) >= 10 {
        fmt.Printf("üèÜ Les 10 plus grands nombres premiers: ")
        for i := len(primes) - 10; i < len(primes); i++ {
            fmt.Printf("%d ", primes[i])
        }
        fmt.Println()
    }
}
```

### Version optimis√©e avec batch processing

```go
// PrimeBatch repr√©sente un lot de nombres √† tester
type PrimeBatch struct {
    Start int
    End   int
}

// PrimeBatchResult repr√©sente les r√©sultats d'un lot
type PrimeBatchResult struct {
    Primes  []int
    Count   int
    Elapsed time.Duration
}

func primeBatchWorker(id int, batches <-chan PrimeBatch, results chan<- PrimeBatchResult, wg *sync.WaitGroup) {
    defer wg.Done()

    batchesProcessed := 0
    for batch := range batches {
        start := time.Now()

        var primes []int
        for n := batch.Start; n <= batch.End; n++ {
            if isPrime(n) {
                primes = append(primes, n)
            }
        }

        result := PrimeBatchResult{
            Primes:  primes,
            Count:   batch.End - batch.Start + 1,
            Elapsed: time.Since(start),
        }

        results <- result
        batchesProcessed++

        fmt.Printf("üì¶ Worker %d: batch %d-%d termin√© (%d premiers trouv√©s)\n",
                  id, batch.Start, batch.End, len(primes))
    }

    fmt.Printf("üèÅ Worker %d termin√© (%d batches trait√©s)\n", id, batchesProcessed)
}

func optimizedPrimeWorkerPool() {
    const (
        numWorkers = 4
        maxNumber  = 10000
        batchSize  = 500
    )

    batches := make(chan PrimeBatch, 20)
    results := make(chan PrimeBatchResult, 20)

    var wg sync.WaitGroup

    startTime := time.Now()

    // D√©marrer les workers
    for w := 1; w <= numWorkers; w++ {
        wg.Add(1)
        go primeBatchWorker(w, batches, results, &wg)
    }

    // Cr√©er les batches
    go func() {
        for start := 1; start <= maxNumber; start += batchSize {
            end := start + batchSize - 1
            if end > maxNumber {
                end = maxNumber
            }

            batch := PrimeBatch{
                Start: start,
                End:   end,
            }
            batches <- batch
        }
        close(batches)
    }()

    // Collecter les r√©sultats
    go func() {
        wg.Wait()
        close(results)
    }()

    // Analyser les r√©sultats
    var allPrimes []int
    var totalNumbers int

    for result := range results {
        allPrimes = append(allPrimes, result.Primes...)
        totalNumbers += result.Count
    }

    fmt.Printf("üéâ Version optimis√©e termin√©e en %v\n", time.Since(startTime))
    fmt.Printf("üìä %d nombres premiers trouv√©s sur %d test√©s\n", len(allPrimes), totalNumbers)
}
```

---

## Exercice 2 : Simulateur de requ√™tes HTTP

### Solution compl√®te

```go
package main

import (
    "errors"
    "fmt"
    "math/rand"
    "sync"
    "time"
)

// HTTPRequest repr√©sente une requ√™te HTTP √† traiter
type HTTPRequest struct {
    ID       int
    URL      string
    Method   string
    Retries  int
    MaxRetries int
}

// HTTPResponse repr√©sente la r√©ponse d'une requ√™te
type HTTPResponse struct {
    RequestID    int
    URL          string
    StatusCode   int
    Success      bool
    Error        error
    Duration     time.Duration
    Attempts     int
}

// HTTPStats contient les statistiques globales
type HTTPStats struct {
    TotalRequests    int
    SuccessfulReqs   int
    FailedReqs       int
    TotalDuration    time.Duration
    AverageDuration  time.Duration
    TotalRetries     int
    MaxDuration      time.Duration
    MinDuration      time.Duration
}

// simulateHTTPRequest simule un appel HTTP avec latence et erreurs al√©atoires
func simulateHTTPRequest(req HTTPRequest) HTTPResponse {
    start := time.Now()

    // Latence variable entre 50ms et 500ms
    latency := time.Duration(50+rand.Intn(450)) * time.Millisecond
    time.Sleep(latency)

    // 20% de chance d'erreur
    success := rand.Float32() > 0.2

    response := HTTPResponse{
        RequestID: req.ID,
        URL:       req.URL,
        Duration:  time.Since(start),
        Attempts:  req.Retries + 1,
    }

    if success {
        // Codes de succ√®s possibles
        codes := []int{200, 201, 202, 204}
        response.StatusCode = codes[rand.Intn(len(codes))]
        response.Success = true
    } else {
        // Codes d'erreur possibles
        codes := []int{400, 401, 403, 404, 500, 502, 503, 504}
        response.StatusCode = codes[rand.Intn(len(codes))]
        response.Success = false
        response.Error = fmt.Errorf("HTTP %d: request failed", response.StatusCode)
    }

    return response
}

// httpWorker traite les requ√™tes HTTP avec retry automatique
func httpWorker(id int, requests <-chan HTTPRequest, responses chan<- HTTPResponse,
                retryQueue chan<- HTTPRequest, wg *sync.WaitGroup) {
    defer wg.Done()

    processed := 0
    for req := range requests {
        fmt.Printf("üåê Worker %d traite requ√™te %d: %s (tentative %d)\n",
                  id, req.ID, req.URL, req.Retries+1)

        response := simulateHTTPRequest(req)

        // Si √©chec et des tentatives restantes
        if !response.Success && req.Retries < req.MaxRetries {
            fmt.Printf("‚ö†Ô∏è Worker %d: √©chec requ√™te %d (code %d), retry...\n",
                      id, req.ID, response.StatusCode)

            // Programmer un retry avec backoff
            retryReq := req
            retryReq.Retries++

            go func() {
                // Backoff exponentiel: 100ms, 200ms, 400ms...
                backoff := time.Duration(100*(1<<uint(req.Retries))) * time.Millisecond
                time.Sleep(backoff)
                retryQueue <- retryReq
            }()
        } else {
            // Requ√™te termin√©e (succ√®s ou √©checs max atteints)
            if response.Success {
                fmt.Printf("‚úÖ Worker %d: requ√™te %d r√©ussie (code %d) en %v\n",
                          id, req.ID, response.StatusCode, response.Duration)
            } else {
                fmt.Printf("‚ùå Worker %d: requ√™te %d d√©finitivement √©chou√©e apr√®s %d tentatives\n",
                          id, req.ID, response.Attempts)
            }

            responses <- response
            processed++
        }
    }

    fmt.Printf("üèÅ Worker %d termin√© (%d requ√™tes trait√©es)\n", id, processed)
}

// retryHandler g√®re la file des retry
func retryHandler(retryQueue <-chan HTTPRequest, mainQueue chan<- HTTPRequest, done <-chan bool) {
    for {
        select {
        case req := <-retryQueue:
            mainQueue <- req
        case <-done:
            return
        }
    }
}

func httpSimulatorPool() {
    const (
        numWorkers     = 5
        numRequests    = 50
        maxRetries     = 2
        queueSize      = 100
    )

    // Channels
    requests := make(chan HTTPRequest, queueSize)
    responses := make(chan HTTPResponse, queueSize)
    retryQueue := make(chan HTTPRequest, queueSize)
    done := make(chan bool)

    var wg sync.WaitGroup

    fmt.Printf("üöÄ D√©marrage du simulateur HTTP avec %d workers\n", numWorkers)
    fmt.Printf("üìä Configuration: %d requ√™tes, %d tentatives max par requ√™te\n",
              numRequests, maxRetries+1)

    startTime := time.Now()

    // D√©marrer le gestionnaire de retry
    go retryHandler(retryQueue, requests, done)

    // D√©marrer les workers
    for w := 1; w <= numWorkers; w++ {
        wg.Add(1)
        go httpWorker(w, requests, responses, retryQueue, &wg)
    }

    // G√©n√©rer les requ√™tes initiales
    go func() {
        endpoints := []string{
            "https://api.example.com/users",
            "https://api.example.com/posts",
            "https://api.example.com/comments",
            "https://api.example.com/albums",
            "https://api.example.com/photos",
        }

        methods := []string{"GET", "POST", "PUT", "DELETE"}

        for i := 1; i <= numRequests; i++ {
            req := HTTPRequest{
                ID:         i,
                URL:        endpoints[rand.Intn(len(endpoints))],
                Method:     methods[rand.Intn(len(methods))],
                Retries:    0,
                MaxRetries: maxRetries,
            }
            requests <- req
        }
    }()

    // Collecter les r√©ponses
    go func() {
        wg.Wait()
        close(responses)
        done <- true
    }()

    // Analyser les r√©sultats
    stats := HTTPStats{
        MinDuration: time.Hour, // Valeur initiale √©lev√©e
    }

    statusCodes := make(map[int]int)
    var successDurations []time.Duration

    fmt.Println("üìä Collecte des r√©sultats...")

    for response := range responses {
        stats.TotalRequests++
        stats.TotalDuration += response.Duration
        stats.TotalRetries += response.Attempts - 1

        // Mettre √† jour min/max duration
        if response.Duration > stats.MaxDuration {
            stats.MaxDuration = response.Duration
        }
        if response.Duration < stats.MinDuration {
            stats.MinDuration = response.Duration
        }

        // Compter les codes de statut
        statusCodes[response.StatusCode]++

        if response.Success {
            stats.SuccessfulReqs++
            successDurations = append(successDurations, response.Duration)
        } else {
            stats.FailedReqs++
        }
    }

    // Calculer la dur√©e moyenne
    if stats.TotalRequests > 0 {
        stats.AverageDuration = stats.TotalDuration / time.Duration(stats.TotalRequests)
    }

    totalElapsed := time.Since(startTime)

    // Afficher les statistiques d√©taill√©es
    fmt.Printf("\nüéâ Simulation termin√©e en %v\n", totalElapsed)
    fmt.Printf("üìà Statistiques globales:\n")
    fmt.Printf("   üìä Requ√™tes totales: %d\n", stats.TotalRequests)
    fmt.Printf("   ‚úÖ Succ√®s: %d (%.1f%%)\n", stats.SuccessfulReqs,
              float64(stats.SuccessfulReqs)/float64(stats.TotalRequests)*100)
    fmt.Printf("   ‚ùå √âchecs: %d (%.1f%%)\n", stats.FailedReqs,
              float64(stats.FailedReqs)/float64(stats.TotalRequests)*100)
    fmt.Printf("   üîÑ Total retry: %d\n", stats.TotalRetries)
    fmt.Printf("   ‚è±Ô∏è Dur√©e moyenne: %v\n", stats.AverageDuration)
    fmt.Printf("   ‚ö° Dur√©e min: %v\n", stats.MinDuration)
    fmt.Printf("   üêå Dur√©e max: %v\n", stats.MaxDuration)
    fmt.Printf("   üöÄ Requ√™tes/sec: %.1f\n", float64(stats.TotalRequests)/totalElapsed.Seconds())

    // Afficher la distribution des codes de statut
    fmt.Printf("\nüìä Distribution des codes de statut:\n")
    for code, count := range statusCodes {
        percentage := float64(count) / float64(stats.TotalRequests) * 100
        emoji := "‚úÖ"
        if code >= 400 {
            emoji = "‚ùå"
        }
        fmt.Printf("   %s %d: %d (%.1f%%)\n", emoji, code, count, percentage)
    }

    // Calculer la m√©diane pour les requ√™tes r√©ussies
    if len(successDurations) > 0 {
        // Tri simple pour trouver la m√©diane
        for i := 0; i < len(successDurations)-1; i++ {
            for j := 0; j < len(successDurations)-i-1; j++ {
                if successDurations[j] > successDurations[j+1] {
                    successDurations[j], successDurations[j+1] = successDurations[j+1], successDurations[j]
                }
            }
        }

        median := successDurations[len(successDurations)/2]
        fmt.Printf("\nüìê M√©diane des requ√™tes r√©ussies: %v\n", median)
    }
}

// Version avec m√©triques en temps r√©el
func httpSimulatorWithMetrics() {
    // M√©triques en temps r√©el
    metrics := struct {
        sync.RWMutex
        completed   int
        successful  int
        failed      int
        inProgress  int
    }{}

    // Moniteur des m√©triques
    go func() {
        ticker := time.NewTicker(2 * time.Second)
        defer ticker.Stop()

        for range ticker.C {
            metrics.RLock()
            fmt.Printf("üìä Temps r√©el - Termin√©es: %d, Succ√®s: %d, √âchecs: %d, En cours: %d\n",
                      metrics.completed, metrics.successful, metrics.failed, metrics.inProgress)
            metrics.RUnlock()
        }
    }()

    // Le reste de l'impl√©mentation avec mise √† jour des m√©triques...
}

func main() {
    rand.Seed(time.Now().UnixNano())

    fmt.Println("=== Exercice 1: Calculateur de nombres premiers ===")
    primeWorkerPool()

    fmt.Println("\n=== Version optimis√©e avec batches ===")
    optimizedPrimeWorkerPool()

    fmt.Println("\n=== Exercice 2: Simulateur de requ√™tes HTTP ===")
    httpSimulatorPool()
}
```

## Points cl√©s des solutions

### Exercice 1 - Nombres premiers

**Fonctionnalit√©s** :
- ‚úÖ Algorithme optimis√© de test de primalit√©
- ‚úÖ Worker pool avec 6 workers
- ‚úÖ Statistiques d√©taill√©es (temps, nombres trouv√©s)
- ‚úÖ Version optimis√©e avec batch processing
- ‚úÖ Suivi des performances en temps r√©el

**Optimisations** :
- Test jusqu'√† ‚àön seulement
- √âviter les nombres pairs
- Batch processing pour r√©duire l'overhead

### Exercice 2 - Simulateur HTTP

**Fonctionnalit√©s** :
- ‚úÖ Simulation r√©aliste avec latences variables
- ‚úÖ 20% de taux d'erreur comme demand√©
- ‚úÖ Retry automatique avec backoff exponentiel
- ‚úÖ 3 tentatives maximum par requ√™te
- ‚úÖ Statistiques compl√®tes et codes de statut
- ‚úÖ M√©triques en temps r√©el optionnelles

**Patterns utilis√©s** :
- Queue s√©par√©e pour les retry
- Backoff exponentiel (100ms, 200ms, 400ms...)
- Gestion des codes HTTP r√©alistes
- Monitoring en temps r√©el

Ces solutions d√©montrent l'utilisation pratique des worker pools pour des probl√®mes r√©els avec gestion d'erreurs, retry, et monitoring !

‚è≠Ô∏è
