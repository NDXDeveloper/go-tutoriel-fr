üîù Retour au [Sommaire](/SOMMAIRE.md)

# 14-4 : Connexions et pools

## Introduction

Imaginez un restaurant o√π il n'y aurait qu'un seul serveur pour tous les clients. Ce serait tr√®s lent ! Les **pools de connexions** fonctionnent comme une √©quipe de serveurs : plusieurs connexions sont pr√™tes √† servir simultan√©ment vos requ√™tes de base de donn√©es.

### Qu'est-ce qu'une connexion de base de donn√©es ?

Une **connexion** est un "canal de communication" entre votre application Go et votre base de donn√©es. C'est comme une ligne t√©l√©phonique qui permet d'envoyer des requ√™tes SQL et de recevoir les r√©sultats.

### Qu'est-ce qu'un pool de connexions ?

Un **pool de connexions** est un ensemble de connexions pr√©-√©tablies et r√©utilisables. Au lieu de cr√©er une nouvelle connexion pour chaque requ√™te (co√ªteux), on emprunte une connexion du pool, on l'utilise, puis on la remet dans le pool.

## Pourquoi les pools sont-ils importants ?

### Sans pool (mauvaise approche) :
```go
// ‚ùå Mauvais : cr√©er une nouvelle connexion √† chaque fois
func obtenirUtilisateur(id int) (*Utilisateur, error) {
    // Nouvelle connexion (co√ªteuse !)
    db, err := sql.Open("postgres", "connection_string")
    if err != nil {
        return nil, err
    }
    defer db.Close() // Ferme la connexion apr√®s usage

    // Faire la requ√™te...
    return user, nil
}
```

### Avec pool (bonne approche) :
```go
// ‚úÖ Bon : r√©utiliser les connexions d'un pool
var db *sql.DB // Pool de connexions global

func init() {
    // Cr√©er le pool une seule fois au d√©marrage
    db, _ = sql.Open("postgres", "connection_string")
    configurePool(db)
}

func obtenirUtilisateur(id int) (*Utilisateur, error) {
    // Emprunter une connexion du pool
    // Pas besoin de db.Close() !
    return user, nil
}
```

## Avantages des pools de connexions

- üöÄ **Performance** : Pas de d√©lai de cr√©ation/destruction
- üí∞ **√âconomie de ressources** : R√©utilisation des connexions
- üîí **Contr√¥le de charge** : Limite le nombre de connexions simultan√©es
- üõ°Ô∏è **Stabilit√©** : √âvite la surcharge de la base de donn√©es
- ‚ö° **Rapidit√©** : Connexions d√©j√† √©tablies et pr√™tes

## Configuration de base avec database/sql

### Param√®tres essentiels

```go
package main

import (
    "database/sql"
    "fmt"
    "time"

    _ "github.com/lib/pq" // Driver PostgreSQL
)

func configurerPool(db *sql.DB) {
    // Nombre maximum de connexions ouvertes
    db.SetMaxOpenConns(25)

    // Nombre maximum de connexions inactives dans le pool
    db.SetMaxIdleConns(25)

    // Dur√©e de vie maximum d'une connexion
    db.SetConnMaxLifetime(5 * time.Minute)

    // Dur√©e maximum d'inactivit√© avant fermeture
    db.SetConnMaxIdleTime(1 * time.Minute)
}

func main() {
    // Cr√©er le pool de connexions
    db, err := sql.Open("postgres",
        "host=localhost user=myuser password=mypass dbname=mydb sslmode=disable")
    if err != nil {
        panic(err)
    }
    defer db.Close()

    // Configurer le pool
    configurerPool(db)

    // Tester la connexion
    if err := db.Ping(); err != nil {
        panic("Impossible de se connecter √† la base de donn√©es")
    }

    fmt.Println("Pool de connexions configur√© et test√© !")

    // Utiliser la base de donn√©es...
    exempleUtilisation(db)
}

func exempleUtilisation(db *sql.DB) {
    // Cette requ√™te utilise automatiquement le pool
    rows, err := db.Query("SELECT id, nom FROM utilisateurs LIMIT 5")
    if err != nil {
        fmt.Printf("Erreur requ√™te: %v\n", err)
        return
    }
    defer rows.Close()

    fmt.Println("Utilisateurs:")
    for rows.Next() {
        var id int
        var nom string
        rows.Scan(&id, &nom)
        fmt.Printf("- %d: %s\n", id, nom)
    }
}
```

### Explication des param√®tres

#### SetMaxOpenConns(n)
```go
db.SetMaxOpenConns(25)
```
- **D√©finition** : Nombre maximum de connexions simultan√©es
- **Par d√©faut** : Illimit√© (peut √™tre dangereux !)
- **Recommandation** : 10-30 pour la plupart des applications

#### SetMaxIdleConns(n)
```go
db.SetMaxIdleConns(10)
```
- **D√©finition** : Connexions gard√©es ouvertes en "standby"
- **Par d√©faut** : 2
- **Recommandation** : Environ la moiti√© de MaxOpenConns

#### SetConnMaxLifetime(duration)
```go
db.SetConnMaxLifetime(5 * time.Minute)
```
- **D√©finition** : Dur√©e de vie maximum d'une connexion
- **Pourquoi** : √âviter les connexions "zombies"
- **Recommandation** : 5-30 minutes

#### SetConnMaxIdleTime(duration)
```go
db.SetConnMaxIdleTime(30 * time.Second)
```
- **D√©finition** : Temps d'inactivit√© avant fermeture
- **Pourquoi** : Lib√©rer les ressources inutilis√©es
- **Recommandation** : 30 secondes √† 2 minutes

## Configuration avec GORM

GORM utilise `database/sql` en arri√®re-plan, donc les m√™mes principes s'appliquent :

```go
package main

import (
    "log"
    "time"

    "gorm.io/driver/postgres"
    "gorm.io/gorm"
    "gorm.io/gorm/logger"
)

type Utilisateur struct {
    gorm.Model
    Nom   string
    Email string
}

func configurerGORM() *gorm.DB {
    // Configuration de la connexion
    dsn := "host=localhost user=myuser password=mypass dbname=mydb port=5432 sslmode=disable"

    // Configuration GORM avec logger
    config := &gorm.Config{
        Logger: logger.Default.LogMode(logger.Info),
    }

    // Ouvrir la connexion
    db, err := gorm.Open(postgres.Open(dsn), config)
    if err != nil {
        log.Fatal("Erreur connexion GORM:", err)
    }

    // R√©cup√©rer l'instance SQL sous-jacente
    sqlDB, err := db.DB()
    if err != nil {
        log.Fatal("Erreur r√©cup√©ration SQL DB:", err)
    }

    // Configurer le pool
    sqlDB.SetMaxOpenConns(20)
    sqlDB.SetMaxIdleConns(10)
    sqlDB.SetConnMaxLifetime(5 * time.Minute)
    sqlDB.SetConnMaxIdleTime(1 * time.Minute)

    log.Println("Pool GORM configur√©")
    return db
}

func main() {
    db := configurerGORM()

    // Migration automatique
    db.AutoMigrate(&Utilisateur{})

    // Test d'utilisation
    user := Utilisateur{Nom: "Alice", Email: "alice@example.com"}
    db.Create(&user)

    var users []Utilisateur
    db.Find(&users)

    log.Printf("Trouv√© %d utilisateurs", len(users))
}
```

## Monitoring et statistiques

### Surveiller l'√©tat du pool

```go
package main

import (
    "database/sql"
    "fmt"
    "log"
    "time"
)

type PoolMonitor struct {
    db *sql.DB
}

func NewPoolMonitor(db *sql.DB) *PoolMonitor {
    return &PoolMonitor{db: db}
}

func (pm *PoolMonitor) AfficherStats() {
    stats := pm.db.Stats()

    fmt.Println("=== STATISTIQUES DU POOL ===")
    fmt.Printf("Connexions ouvertes: %d\n", stats.OpenConnections)
    fmt.Printf("Connexions en cours d'utilisation: %d\n", stats.InUse)
    fmt.Printf("Connexions inactives: %d\n", stats.Idle)
    fmt.Printf("Attentes de connexion: %d\n", stats.WaitCount)
    fmt.Printf("Dur√©e d'attente totale: %v\n", stats.WaitDuration)
    fmt.Printf("Connexions ferm√©es (max lifetime): %d\n", stats.MaxLifetimeClosed)
    fmt.Printf("Connexions ferm√©es (max idle): %d\n", stats.MaxIdleClosed)
    fmt.Printf("Connexions ferm√©es (max idle time): %d\n", stats.MaxIdleTimeClosed)
    fmt.Println("===============================")
}

func (pm *PoolMonitor) SurveillanceEnContinu() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        stats := pm.db.Stats()

        // Alertes simples
        if stats.WaitCount > 100 {
            log.Printf("‚ö†Ô∏è  ALERTE: Trop d'attentes de connexion (%d)", stats.WaitCount)
        }

        if stats.OpenConnections >= 20 { // Supposons max = 25
            log.Printf("‚ö†Ô∏è  ALERTE: Pool presque plein (%d/25)", stats.OpenConnections)
        }

        // Log p√©riodique
        log.Printf("Pool: %d ouvertes, %d utilis√©es, %d inactives",
            stats.OpenConnections, stats.InUse, stats.Idle)
    }
}

// Exemple d'utilisation
func exempleMonitoring() {
    db, err := sql.Open("postgres", "connection_string")
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()

    // Configuration du pool
    db.SetMaxOpenConns(25)
    db.SetMaxIdleConns(10)
    db.SetConnMaxLifetime(5 * time.Minute)

    // Cr√©er le moniteur
    monitor := NewPoolMonitor(db)

    // Surveillance en arri√®re-plan
    go monitor.SurveillanceEnContinu()

    // Affichage manuel
    monitor.AfficherStats()

    // Simulation de charge
    for i := 0; i < 100; i++ {
        go func(id int) {
            rows, err := db.Query("SELECT 1")
            if err != nil {
                log.Printf("Erreur requ√™te %d: %v", id, err)
                return
            }
            rows.Close()
        }(i)
    }

    time.Sleep(10 * time.Second)
    monitor.AfficherStats()
}
```

## Test de charge et optimisation

### Simulateur de charge

```go
package main

import (
    "database/sql"
    "fmt"
    "log"
    "sync"
    "time"
)

type LoadTester struct {
    db *sql.DB
}

func NewLoadTester(db *sql.DB) *LoadTester {
    return &LoadTester{db: db}
}

func (lt *LoadTester) TestConcurrency(nbRoutines, nbRequetesParRoutine int) {
    fmt.Printf("Test de charge: %d goroutines √ó %d requ√™tes\n",
        nbRoutines, nbRequetesParRoutine)

    var wg sync.WaitGroup
    start := time.Now()

    erreurs := make(chan error, nbRoutines*nbRequetesParRoutine)

    for i := 0; i < nbRoutines; i++ {
        wg.Add(1)
        go func(routineID int) {
            defer wg.Done()

            for j := 0; j < nbRequetesParRoutine; j++ {
                if err := lt.requeteSimple(); err != nil {
                    erreurs <- fmt.Errorf("routine %d, requ√™te %d: %v",
                        routineID, j, err)
                }
            }
        }(i)
    }

    wg.Wait()
    close(erreurs)

    duration := time.Since(start)
    totalRequetes := nbRoutines * nbRequetesParRoutine

    // Compter les erreurs
    nbErreurs := 0
    for err := range erreurs {
        log.Println("Erreur:", err)
        nbErreurs++
    }

    fmt.Printf("R√©sultats du test:\n")
    fmt.Printf("- Dur√©e totale: %v\n", duration)
    fmt.Printf("- Requ√™tes totales: %d\n", totalRequetes)
    fmt.Printf("- Requ√™tes r√©ussies: %d\n", totalRequetes-nbErreurs)
    fmt.Printf("- Erreurs: %d\n", nbErreurs)
    fmt.Printf("- Requ√™tes/seconde: %.2f\n",
        float64(totalRequetes)/duration.Seconds())
}

func (lt *LoadTester) requeteSimple() error {
    rows, err := lt.db.Query("SELECT 1")
    if err != nil {
        return err
    }
    defer rows.Close()

    for rows.Next() {
        var dummy int
        if err := rows.Scan(&dummy); err != nil {
            return err
        }
    }

    return rows.Err()
}

// Benchmarker diff√©rentes configurations
func benchmarkConfigurations() {
    configs := []struct {
        nom           string
        maxOpen       int
        maxIdle       int
        maxLifetime   time.Duration
    }{
        {"Conservative", 5, 2, 1 * time.Minute},
        {"Balanced", 10, 5, 5 * time.Minute},
        {"Aggressive", 25, 10, 10 * time.Minute},
        {"High-Performance", 50, 25, 30 * time.Minute},
    }

    for _, config := range configs {
        fmt.Printf("\n=== Test configuration: %s ===\n", config.nom)

        db, err := sql.Open("postgres", "connection_string")
        if err != nil {
            log.Printf("Erreur connexion pour %s: %v", config.nom, err)
            continue
        }

        db.SetMaxOpenConns(config.maxOpen)
        db.SetMaxIdleConns(config.maxIdle)
        db.SetConnMaxLifetime(config.maxLifetime)

        tester := NewLoadTester(db)
        tester.TestConcurrency(10, 50) // 10 goroutines √ó 50 requ√™tes

        db.Close()
    }
}
```

## Gestion des timeouts

### Configuration des timeouts avec Context

```go
package main

import (
    "context"
    "database/sql"
    "fmt"
    "time"
)

type DatabaseManager struct {
    db *sql.DB
}

func NewDatabaseManager(connectionString string) (*DatabaseManager, error) {
    db, err := sql.Open("postgres", connectionString)
    if err != nil {
        return nil, err
    }

    // Configuration optimis√©e avec timeouts
    db.SetMaxOpenConns(20)
    db.SetMaxIdleConns(10)
    db.SetConnMaxLifetime(5 * time.Minute)
    db.SetConnMaxIdleTime(30 * time.Second)

    return &DatabaseManager{db: db}, nil
}

func (dm *DatabaseManager) RequeteAvecTimeout(query string, timeout time.Duration, args ...interface{}) (*sql.Rows, error) {
    // Cr√©er un context avec timeout
    ctx, cancel := context.WithTimeout(context.Background(), timeout)
    defer cancel()

    // Ex√©cuter la requ√™te avec timeout
    return dm.db.QueryContext(ctx, query, args...)
}

func (dm *DatabaseManager) ExempleUtilisation() {
    // Requ√™te rapide (timeout court)
    rows, err := dm.RequeteAvecTimeout(
        "SELECT id, nom FROM utilisateurs LIMIT 10",
        2*time.Second)
    if err != nil {
        fmt.Printf("Erreur requ√™te rapide: %v\n", err)
        return
    }
    rows.Close()

    // Requ√™te complexe (timeout plus long)
    rows, err = dm.RequeteAvecTimeout(`
        SELECT u.nom, COUNT(p.id) as nb_posts
        FROM utilisateurs u
        LEFT JOIN posts p ON u.id = p.user_id
        GROUP BY u.id, u.nom
        ORDER BY nb_posts DESC`,
        10*time.Second)
    if err != nil {
        fmt.Printf("Erreur requ√™te complexe: %v\n", err)
        return
    }
    rows.Close()

    fmt.Println("Requ√™tes ex√©cut√©es avec succ√®s")
}

// Context avec deadline absolue
func (dm *DatabaseManager) RequeteAvecDeadline(query string, deadline time.Time, args ...interface{}) (*sql.Rows, error) {
    ctx, cancel := context.WithDeadline(context.Background(), deadline)
    defer cancel()

    return dm.db.QueryContext(ctx, query, args...)
}

// Context annulable manuellement
func (dm *DatabaseManager) RequeteAnnulable() {
    ctx, cancel := context.WithCancel(context.Background())

    // Annuler apr√®s 5 secondes
    go func() {
        time.Sleep(5 * time.Second)
        cancel()
    }()

    rows, err := dm.db.QueryContext(ctx, "SELECT pg_sleep(10)") // Requ√™te longue
    if err != nil {
        fmt.Printf("Requ√™te annul√©e: %v\n", err)
        return
    }
    rows.Close()
}
```

## Configuration selon l'environnement

### Configuration adaptive

```go
package main

import (
    "database/sql"
    "fmt"
    "os"
    "strconv"
    "time"
)

type EnvironmentConfig struct {
    MaxOpenConns    int
    MaxIdleConns    int
    ConnMaxLifetime time.Duration
    ConnMaxIdleTime time.Duration
}

func getConfigFromEnv() EnvironmentConfig {
    env := os.Getenv("APP_ENV")

    switch env {
    case "production":
        return EnvironmentConfig{
            MaxOpenConns:    50,
            MaxIdleConns:    25,
            ConnMaxLifetime: 30 * time.Minute,
            ConnMaxIdleTime: 5 * time.Minute,
        }
    case "staging":
        return EnvironmentConfig{
            MaxOpenConns:    20,
            MaxIdleConns:    10,
            ConnMaxLifetime: 10 * time.Minute,
            ConnMaxIdleTime: 2 * time.Minute,
        }
    case "development":
        return EnvironmentConfig{
            MaxOpenConns:    5,
            MaxIdleConns:    2,
            ConnMaxLifetime: 5 * time.Minute,
            ConnMaxIdleTime: 1 * time.Minute,
        }
    default:
        // Configuration par d√©faut
        return EnvironmentConfig{
            MaxOpenConns:    10,
            MaxIdleConns:    5,
            ConnMaxLifetime: 5 * time.Minute,
            ConnMaxIdleTime: 1 * time.Minute,
        }
    }
}

func getConfigFromEnvVars() EnvironmentConfig {
    config := EnvironmentConfig{}

    // Lire depuis les variables d'environnement avec valeurs par d√©faut
    if val := os.Getenv("DB_MAX_OPEN_CONNS"); val != "" {
        if parsed, err := strconv.Atoi(val); err == nil {
            config.MaxOpenConns = parsed
        }
    } else {
        config.MaxOpenConns = 25
    }

    if val := os.Getenv("DB_MAX_IDLE_CONNS"); val != "" {
        if parsed, err := strconv.Atoi(val); err == nil {
            config.MaxIdleConns = parsed
        }
    } else {
        config.MaxIdleConns = 10
    }

    if val := os.Getenv("DB_CONN_MAX_LIFETIME"); val != "" {
        if parsed, err := time.ParseDuration(val); err == nil {
            config.ConnMaxLifetime = parsed
        }
    } else {
        config.ConnMaxLifetime = 5 * time.Minute
    }

    if val := os.Getenv("DB_CONN_MAX_IDLE_TIME"); val != "" {
        if parsed, err := time.ParseDuration(val); err == nil {
            config.ConnMaxIdleTime = parsed
        }
    } else {
        config.ConnMaxIdleTime = 1 * time.Minute
    }

    return config
}

func configureDatabase(connectionString string) (*sql.DB, error) {
    db, err := sql.Open("postgres", connectionString)
    if err != nil {
        return nil, err
    }

    // Choisir la m√©thode de configuration
    config := getConfigFromEnv() // ou getConfigFromEnvVars()

    // Appliquer la configuration
    db.SetMaxOpenConns(config.MaxOpenConns)
    db.SetMaxIdleConns(config.MaxIdleConns)
    db.SetConnMaxLifetime(config.ConnMaxLifetime)
    db.SetConnMaxIdleTime(config.ConnMaxIdleTime)

    fmt.Printf("Base de donn√©es configur√©e pour %s:\n", os.Getenv("APP_ENV"))
    fmt.Printf("- MaxOpenConns: %d\n", config.MaxOpenConns)
    fmt.Printf("- MaxIdleConns: %d\n", config.MaxIdleConns)
    fmt.Printf("- ConnMaxLifetime: %v\n", config.ConnMaxLifetime)
    fmt.Printf("- ConnMaxIdleTime: %v\n", config.ConnMaxIdleTime)

    return db, nil
}
```

## Patterns avanc√©s

### Pool Manager avec retry automatique

```go
package main

import (
    "database/sql"
    "fmt"
    "log"
    "time"
)

type PoolManager struct {
    db     *sql.DB
    config EnvironmentConfig
}

func NewPoolManager(connectionString string) (*PoolManager, error) {
    pm := &PoolManager{
        config: getConfigFromEnv(),
    }

    if err := pm.connect(connectionString); err != nil {
        return nil, err
    }

    // D√©marrer la surveillance
    go pm.healthCheck()

    return pm, nil
}

func (pm *PoolManager) connect(connectionString string) error {
    db, err := sql.Open("postgres", connectionString)
    if err != nil {
        return err
    }

    // Configuration du pool
    db.SetMaxOpenConns(pm.config.MaxOpenConns)
    db.SetMaxIdleConns(pm.config.MaxIdleConns)
    db.SetConnMaxLifetime(pm.config.ConnMaxLifetime)
    db.SetConnMaxIdleTime(pm.config.ConnMaxIdleTime)

    // Test de connexion
    if err := db.Ping(); err != nil {
        db.Close()
        return err
    }

    pm.db = db
    return nil
}

func (pm *PoolManager) healthCheck() {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        if err := pm.db.Ping(); err != nil {
            log.Printf("‚ùå Health check failed: %v", err)
            pm.handleConnectionLoss()
        } else {
            stats := pm.db.Stats()
            if stats.WaitCount > 0 {
                log.Printf("‚ö†Ô∏è  Pool pressure detected: %d waits", stats.WaitCount)
            }
        }
    }
}

func (pm *PoolManager) handleConnectionLoss() {
    log.Println("üîÑ Attempting to reconnect...")

    // Fermer la connexion actuelle
    if pm.db != nil {
        pm.db.Close()
    }

    // Retry avec backoff exponentiel
    for attempt := 1; attempt <= 5; attempt++ {
        time.Sleep(time.Duration(attempt*attempt) * time.Second)

        if err := pm.connect("connection_string"); err != nil {
            log.Printf("Reconnection attempt %d failed: %v", attempt, err)
        } else {
            log.Printf("‚úÖ Reconnected successfully after %d attempts", attempt)
            return
        }
    }

    log.Fatal("üí• Failed to reconnect after 5 attempts")
}

func (pm *PoolManager) GetDB() *sql.DB {
    return pm.db
}

func (pm *PoolManager) Close() error {
    return pm.db.Close()
}
```

### Circuit Breaker pour la base de donn√©es

```go
package main

import (
    "database/sql"
    "errors"
    "sync"
    "time"
)

type CircuitBreakerState int

const (
    StateClosed CircuitBreakerState = iota
    StateOpen
    StateHalfOpen
)

type CircuitBreaker struct {
    mu          sync.RWMutex
    state       CircuitBreakerState
    failureCount int
    lastFailure time.Time
    threshold   int
    timeout     time.Duration
}

type DatabaseWithCircuitBreaker struct {
    db      *sql.DB
    breaker *CircuitBreaker
}

func NewDatabaseWithCircuitBreaker(db *sql.DB) *DatabaseWithCircuitBreaker {
    return &DatabaseWithCircuitBreaker{
        db: db,
        breaker: &CircuitBreaker{
            threshold: 5,                // 5 √©checs cons√©cutifs
            timeout:   30 * time.Second, // Attendre 30s avant de r√©essayer
        },
    }
}

func (cb *CircuitBreaker) Call(fn func() error) error {
    cb.mu.Lock()
    defer cb.mu.Unlock()

    switch cb.state {
    case StateOpen:
        if time.Since(cb.lastFailure) > cb.timeout {
            cb.state = StateHalfOpen
            cb.failureCount = 0
        } else {
            return errors.New("circuit breaker is open")
        }
    }

    err := fn()

    if err != nil {
        cb.failureCount++
        cb.lastFailure = time.Now()

        if cb.failureCount >= cb.threshold {
            cb.state = StateOpen
        }
        return err
    }

    // Succ√®s
    cb.failureCount = 0
    cb.state = StateClosed
    return nil
}

func (dwcb *DatabaseWithCircuitBreaker) Query(query string, args ...interface{}) (*sql.Rows, error) {
    var rows *sql.Rows
    var err error

    circuitErr := dwcb.breaker.Call(func() error {
        rows, err = dwcb.db.Query(query, args...)
        return err
    })

    if circuitErr != nil {
        return nil, circuitErr
    }

    return rows, err
}
```

## Recommandations par cas d'usage

### Application web classique
```go
func configWebApp(db *sql.DB) {
    db.SetMaxOpenConns(25)              // Trafic mod√©r√©
    db.SetMaxIdleConns(10)              // Garde quelques connexions
    db.SetConnMaxLifetime(5 * time.Minute)  // Renouvellement r√©gulier
    db.SetConnMaxIdleTime(1 * time.Minute)  // Lib√©ration rapide
}
```

### API haute performance
```go
func configHighPerformanceAPI(db *sql.DB) {
    db.SetMaxOpenConns(100)             // Beaucoup de trafic concurrent
    db.SetMaxIdleConns(50)              // Garde beaucoup de connexions pr√™tes
    db.SetConnMaxLifetime(30 * time.Minute) // Dur√©e de vie plus longue
    db.SetConnMaxIdleTime(5 * time.Minute)  // Patience plus longue
}
```

### Application batch/ETL
```go
func configBatchApp(db *sql.DB) {
    db.SetMaxOpenConns(5)               // Peu de concurrence
    db.SetMaxIdleConns(2)               // Minimum de connexions
    db.SetConnMaxLifetime(1 * time.Hour)   // Connexions longue dur√©e
    db.SetConnMaxIdleTime(10 * time.Minute) // Patience pour les pauses
}
```

### Microservice
```go
func configMicroservice(db *sql.DB) {
    db.SetMaxOpenConns(10)              // Charge l√©g√®re
    db.SetMaxIdleConns(3)               // Peu de connexions idle
    db.SetConnMaxLifetime(10 * time.Minute) // Renouvellement mod√©r√©
    db.SetConnMaxIdleTime(2 * time.Minute)  // Lib√©ration rapide
}
```

## Debugging et troubleshooting

### Probl√®mes courants et solutions

#### 1. "too many connections"
```go
// Probl√®me: MaxOpenConns trop √©lev√©
db.SetMaxOpenConns(1000) // ‚ùå Trop !

// Solution: R√©duire et surveiller
db.SetMaxOpenConns(25)   // ‚úÖ Plus raisonnable

// Diagnostic
stats := db.Stats()
if stats.OpenConnections >= maxOpen * 0.8 {
    log.Printf("‚ö†Ô∏è  Pool utilisation: %d/%d", stats.OpenConnections, maxOpen)
}
```

#### 2. Connexions qui "tra√Ænent" (connection leaks)
```go
// ‚ùå Probl√®me: Ne pas fermer les rows
func mauvaisFonction(db *sql.DB) {
    rows, err := db.Query("SELECT * FROM users")
    if err != nil {
        return
    }
    // OOPS! Pas de rows.Close() - fuite de connexion !

    for rows.Next() {
        // traitement...
    }
}

// ‚úÖ Solution: Toujours fermer avec defer
func bonneFonction(db *sql.DB) {
    rows, err := db.Query("SELECT * FROM users")
    if err != nil {
        return
    }
    defer rows.Close() // ‚úÖ Connexion lib√©r√©e automatiquement

    for rows.Next() {
        // traitement...
    }
}

// üîç Diagnostic automatique
func detecterFuites(db *sql.DB) {
    ticker := time.NewTicker(1 * time.Minute)
    defer ticker.Stop()

    var dernierInUse int

    for range ticker.C {
        stats := db.Stats()

        if stats.InUse > dernierInUse {
            log.Printf("üìà Connexions en cours: %d (√©tait %d)",
                stats.InUse, dernierInUse)
        } else if stats.InUse > 0 && stats.InUse == dernierInUse {
            log.Printf("‚ö†Ô∏è  Connexions bloqu√©es? En cours: %d", stats.InUse)
        }

        dernierInUse = stats.InUse
    }
}
```

#### 3. Timeouts et requ√™tes lentes
```go
// ‚ùå Probl√®me: Pas de timeout sur les requ√™tes lentes
func requeteSansTimeout(db *sql.DB) {
    // Cette requ√™te peut bloquer ind√©finiment
    rows, err := db.Query("SELECT * FROM huge_table ORDER BY complex_calculation")
    if err != nil {
        return
    }
    defer rows.Close()
}

// ‚úÖ Solution: Utiliser Context avec timeout
func requeteAvecTimeout(db *sql.DB) {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()

    rows, err := db.QueryContext(ctx, "SELECT * FROM huge_table ORDER BY complex_calculation")
    if err != nil {
        if err == context.DeadlineExceeded {
            log.Println("‚è∞ Requ√™te annul√©e - timeout")
        }
        return
    }
    defer rows.Close()
}

// üîç Surveillance des requ√™tes lentes
type SlowQueryDetector struct {
    db        *sql.DB
    threshold time.Duration
}

func (sqd *SlowQueryDetector) QueryWithLogging(query string, args ...interface{}) (*sql.Rows, error) {
    start := time.Now()

    rows, err := sqd.db.Query(query, args...)

    duration := time.Since(start)
    if duration > sqd.threshold {
        log.Printf("üêå Requ√™te lente d√©tect√©e: %v\nQuery: %s", duration, query)
    }

    return rows, err
}
```

#### 4. Pool mal dimensionn√©
```go
// üîç Analyseur de charge pour dimensionner le pool
type PoolAnalyzer struct {
    db           *sql.DB
    maxObserved  int
    samples      []int
    startTime    time.Time
}

func NewPoolAnalyzer(db *sql.DB) *PoolAnalyzer {
    return &PoolAnalyzer{
        db:        db,
        samples:   make([]int, 0),
        startTime: time.Now(),
    }
}

func (pa *PoolAnalyzer) StartAnalysis() {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        stats := pa.db.Stats()
        concurrent := stats.InUse

        pa.samples = append(pa.samples, concurrent)

        if concurrent > pa.maxObserved {
            pa.maxObserved = concurrent
            log.Printf("üìä Nouveau pic de concurrence: %d", concurrent)
        }

        // Rapport toutes les minutes
        if len(pa.samples) >= 12 { // 12 √©chantillons = 1 minute
            pa.generateReport()
            pa.samples = pa.samples[:0] // Reset
        }
    }
}

func (pa *PoolAnalyzer) generateReport() {
    if len(pa.samples) == 0 {
        return
    }

    // Calculer moyenne et m√©diane
    sum := 0
    for _, sample := range pa.samples {
        sum += sample
    }
    moyenne := float64(sum) / float64(len(pa.samples))

    // Trier pour la m√©diane
    sorted := make([]int, len(pa.samples))
    copy(sorted, pa.samples)

    // Tri simple
    for i := 0; i < len(sorted); i++ {
        for j := i + 1; j < len(sorted); j++ {
            if sorted[i] > sorted[j] {
                sorted[i], sorted[j] = sorted[j], sorted[i]
            }
        }
    }

    mediane := sorted[len(sorted)/2]

    log.Printf("üìà Rapport de charge (derni√®re minute):")
    log.Printf("   Moyenne: %.1f connexions", moyenne)
    log.Printf("   M√©diane: %d connexions", mediane)
    log.Printf("   Maximum: %d connexions", pa.maxObserved)
    log.Printf("   Recommandation MaxOpenConns: %d", pa.maxObserved*2)
}
```

#### 5. Gestion des erreurs de connexion
```go
type RobustDB struct {
    db           *sql.DB
    retryCount   int
    retryDelay   time.Duration
    circuitOpen  bool
    lastError    time.Time
}

func NewRobustDB(connectionString string) (*RobustDB, error) {
    db, err := sql.Open("postgres", connectionString)
    if err != nil {
        return nil, err
    }

    return &RobustDB{
        db:         db,
        retryCount: 3,
        retryDelay: 1 * time.Second,
    }, nil
}

func (rdb *RobustDB) QueryWithRetry(query string, args ...interface{}) (*sql.Rows, error) {
    // V√©rifier le circuit breaker
    if rdb.circuitOpen && time.Since(rdb.lastError) < 30*time.Second {
        return nil, errors.New("circuit breaker open - too many recent failures")
    }

    var lastErr error

    for attempt := 0; attempt <= rdb.retryCount; attempt++ {
        if attempt > 0 {
            log.Printf("üîÑ Tentative %d/%d pour la requ√™te", attempt+1, rdb.retryCount+1)
            time.Sleep(rdb.retryDelay * time.Duration(attempt))
        }

        rows, err := rdb.db.Query(query, args...)
        if err == nil {
            // Succ√®s - r√©initialiser le circuit breaker
            rdb.circuitOpen = false
            return rows, nil
        }

        lastErr = err

        // Analyser le type d'erreur
        if isConnectionError(err) {
            log.Printf("‚ùå Erreur de connexion: %v", err)
            continue // Retry
        } else {
            // Erreur SQL - ne pas retry
            break
        }
    }

    // Toutes les tentatives ont √©chou√©
    rdb.circuitOpen = true
    rdb.lastError = time.Now()
    return nil, fmt.Errorf("failed after %d attempts: %v", rdb.retryCount+1, lastErr)
}

func isConnectionError(err error) bool {
    errStr := err.Error()
    connectionErrors := []string{
        "connection refused",
        "connection reset",
        "broken pipe",
        "network is unreachable",
        "timeout",
    }

    for _, connErr := range connectionErrors {
        if strings.Contains(errStr, connErr) {
            return true
        }
    }
    return false
}
```

## Monitoring avanc√©

### Dashboard de monitoring en temps r√©el
```go
package main

import (
    "encoding/json"
    "fmt"
    "html/template"
    "net/http"
    "time"
)

type DatabaseMonitor struct {
    db    *sql.DB
    stats []PoolStats
}

type PoolStats struct {
    Timestamp       time.Time `json:"timestamp"`
    OpenConnections int       `json:"openConnections"`
    InUse           int       `json:"inUse"`
    Idle            int       `json:"idle"`
    WaitCount       int64     `json:"waitCount"`
    WaitDuration    string    `json:"waitDuration"`
}

func NewDatabaseMonitor(db *sql.DB) *DatabaseMonitor {
    dm := &DatabaseMonitor{
        db:    db,
        stats: make([]PoolStats, 0),
    }

    // Collecter les stats toutes les 10 secondes
    go dm.collectStats()

    return dm
}

func (dm *DatabaseMonitor) collectStats() {
    ticker := time.NewTicker(10 * time.Second)
    defer ticker.Stop()

    for range ticker.C {
        stats := dm.db.Stats()

        poolStats := PoolStats{
            Timestamp:       time.Now(),
            OpenConnections: stats.OpenConnections,
            InUse:           stats.InUse,
            Idle:            stats.Idle,
            WaitCount:       stats.WaitCount,
            WaitDuration:    stats.WaitDuration.String(),
        }

        dm.stats = append(dm.stats, poolStats)

        // Garder seulement les 100 derniers points (16 minutes)
        if len(dm.stats) > 100 {
            dm.stats = dm.stats[1:]
        }
    }
}

func (dm *DatabaseMonitor) ServeHTTP() {
    http.HandleFunc("/", dm.dashboardHandler)
    http.HandleFunc("/api/stats", dm.statsHandler)

    fmt.Println("Dashboard disponible sur http://localhost:8080")
    http.ListenAndServe(":8080", nil)
}

func (dm *DatabaseMonitor) dashboardHandler(w http.ResponseWriter, r *http.Request) {
    tmpl := `
<!DOCTYPE html>
<html>
<head>
    <title>Database Pool Monitor</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .container { max-width: 1200px; margin: 0 auto; }
        .stats { display: flex; gap: 20px; margin-bottom: 20px; }
        .stat-card {
            background: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            text-align: center;
            flex: 1;
        }
        .chart-container { width: 100%; height: 400px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Database Pool Monitor</h1>

        <div class="stats">
            <div class="stat-card">
                <h3>Connexions ouvertes</h3>
                <div id="openConns">-</div>
            </div>
            <div class="stat-card">
                <h3>En utilisation</h3>
                <div id="inUse">-</div>
            </div>
            <div class="stat-card">
                <h3>Inactives</h3>
                <div id="idle">-</div>
            </div>
            <div class="stat-card">
                <h3>Total attentes</h3>
                <div id="waitCount">-</div>
            </div>
        </div>

        <div class="chart-container">
            <canvas id="chart"></canvas>
        </div>
    </div>

    <script>
        const ctx = document.getElementById('chart').getContext('2d');
        const chart = new Chart(ctx, {
            type: 'line',
            data: {
                labels: [],
                datasets: [{
                    label: 'Connexions ouvertes',
                    data: [],
                    borderColor: 'rgb(75, 192, 192)',
                    tension: 0.1
                }, {
                    label: 'En utilisation',
                    data: [],
                    borderColor: 'rgb(255, 99, 132)',
                    tension: 0.1
                }, {
                    label: 'Inactives',
                    data: [],
                    borderColor: 'rgb(54, 162, 235)',
                    tension: 0.1
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true
                    }
                }
            }
        });

        function updateStats() {
            fetch('/api/stats')
                .then(response => response.json())
                .then(data => {
                    if (data.length > 0) {
                        const latest = data[data.length - 1];
                        document.getElementById('openConns').textContent = latest.openConnections;
                        document.getElementById('inUse').textContent = latest.inUse;
                        document.getElementById('idle').textContent = latest.idle;
                        document.getElementById('waitCount').textContent = latest.waitCount;
                    }

                    // Mettre √† jour le graphique
                    chart.data.labels = data.map(d => new Date(d.timestamp).toLocaleTimeString());
                    chart.data.datasets[0].data = data.map(d => d.openConnections);
                    chart.data.datasets[1].data = data.map(d => d.inUse);
                    chart.data.datasets[2].data = data.map(d => d.idle);
                    chart.update();
                });
        }

        // Mettre √† jour toutes les 5 secondes
        setInterval(updateStats, 5000);
        updateStats(); // Premier chargement
    </script>
</body>
</html>`

    w.Header().Set("Content-Type", "text/html")
    fmt.Fprint(w, tmpl)
}

func (dm *DatabaseMonitor) statsHandler(w http.ResponseWriter, r *http.Request) {
    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(dm.stats)
}

// Exemple d'utilisation
func exempleMonitoring() {
    db, err := sql.Open("postgres", "connection_string")
    if err != nil {
        log.Fatal(err)
    }
    defer db.Close()

    // Configuration du pool
    db.SetMaxOpenConns(25)
    db.SetMaxIdleConns(10)
    db.SetConnMaxLifetime(5 * time.Minute)

    // D√©marrer le monitoring
    monitor := NewDatabaseMonitor(db)
    monitor.ServeHTTP() // Bloquant
}
```

## Exemples concrets d'applications

### 1. API REST avec pool optimis√©
```go
package main

import (
    "context"
    "database/sql"
    "encoding/json"
    "fmt"
    "log"
    "net/http"
    "strconv"
    "time"

    "github.com/gorilla/mux"
)

type APIServer struct {
    db *sql.DB
}

type User struct {
    ID    int    `json:"id"`
    Name  string `json:"name"`
    Email string `json:"email"`
}

func NewAPIServer() *APIServer {
    // Configuration sp√©cifique API REST
    db, err := sql.Open("postgres", "connection_string")
    if err != nil {
        log.Fatal("Erreur connexion:", err)
    }

    // Configuration pour API REST (beaucoup de requ√™tes courtes)
    db.SetMaxOpenConns(50)  // Haute concurrence
    db.SetMaxIdleConns(25)  // Beaucoup de connexions pr√™tes
    db.SetConnMaxLifetime(10 * time.Minute)
    db.SetConnMaxIdleTime(2 * time.Minute)

    return &APIServer{db: db}
}

func (api *APIServer) getUserHandler(w http.ResponseWriter, r *http.Request) {
    vars := mux.Vars(r)
    userID, err := strconv.Atoi(vars["id"])
    if err != nil {
        http.Error(w, "ID invalide", http.StatusBadRequest)
        return
    }

    // Timeout court pour API responsive
    ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
    defer cancel()

    var user User
    err = api.db.QueryRowContext(ctx,
        "SELECT id, name, email FROM users WHERE id = $1", userID).
        Scan(&user.ID, &user.Name, &user.Email)

    if err != nil {
        if err == sql.ErrNoRows {
            http.Error(w, "Utilisateur non trouv√©", http.StatusNotFound)
        } else {
            log.Printf("Erreur BDD: %v", err)
            http.Error(w, "Erreur serveur", http.StatusInternalServerError)
        }
        return
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(user)
}

func (api *APIServer) getUsersHandler(w http.ResponseWriter, r *http.Request) {
    // Timeout plus long pour les listes
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()

    rows, err := api.db.QueryContext(ctx,
        "SELECT id, name, email FROM users ORDER BY id LIMIT 100")
    if err != nil {
        log.Printf("Erreur requ√™te: %v", err)
        http.Error(w, "Erreur serveur", http.StatusInternalServerError)
        return
    }
    defer rows.Close()

    var users []User
    for rows.Next() {
        var user User
        if err := rows.Scan(&user.ID, &user.Name, &user.Email); err != nil {
            log.Printf("Erreur scan: %v", err)
            continue
        }
        users = append(users, user)
    }

    w.Header().Set("Content-Type", "application/json")
    json.NewEncoder(w).Encode(users)
}

func (api *APIServer) Start() {
    r := mux.NewRouter()
    r.HandleFunc("/users/{id}", api.getUserHandler).Methods("GET")
    r.HandleFunc("/users", api.getUsersHandler).Methods("GET")

    log.Println("API d√©marr√©e sur :8080")
    log.Fatal(http.ListenAndServe(":8080", r))
}
```

### 2. Worker pour traitement batch
```go
package main

import (
    "context"
    "database/sql"
    "log"
    "sync"
    "time"
)

type BatchProcessor struct {
    db          *sql.DB
    workerCount int
    batchSize   int
}

func NewBatchProcessor() *BatchProcessor {
    // Configuration pour traitement batch
    db, err := sql.Open("postgres", "connection_string")
    if err != nil {
        log.Fatal("Erreur connexion:", err)
    }

    // Configuration pour batch (longues transactions)
    db.SetMaxOpenConns(10)   // Moins de concurrence
    db.SetMaxIdleConns(5)    // √âconomie de ressources
    db.SetConnMaxLifetime(30 * time.Minute) // Connexions longue dur√©e
    db.SetConnMaxIdleTime(5 * time.Minute)  // Patience entre batches

    return &BatchProcessor{
        db:          db,
        workerCount: 5,
        batchSize:   1000,
    }
}

func (bp *BatchProcessor) ProcessAllUsers() {
    // Canal pour distribuer le travail
    userIDs := make(chan int, bp.batchSize)

    // Lancer les workers
    var wg sync.WaitGroup
    for i := 0; i < bp.workerCount; i++ {
        wg.Add(1)
        go bp.worker(i, userIDs, &wg)
    }

    // Alimenter le canal avec les IDs √† traiter
    go func() {
        defer close(userIDs)

        // Timeout long pour les gros datasets
        ctx, cancel := context.WithTimeout(context.Background(), 1*time.Hour)
        defer cancel()

        rows, err := bp.db.QueryContext(ctx,
            "SELECT id FROM users WHERE status = 'pending' ORDER BY id")
        if err != nil {
            log.Printf("Erreur requ√™te users: %v", err)
            return
        }
        defer rows.Close()

        for rows.Next() {
            var userID int
            if err := rows.Scan(&userID); err != nil {
                log.Printf("Erreur scan: %v", err)
                continue
            }

            select {
            case userIDs <- userID:
            case <-ctx.Done():
                log.Println("Timeout pendant la lecture des users")
                return
            }
        }
    }()

    // Attendre tous les workers
    wg.Wait()
    log.Println("Traitement batch termin√©")
}

func (bp *BatchProcessor) worker(id int, userIDs <-chan int, wg *sync.WaitGroup) {
    defer wg.Done()

    log.Printf("Worker %d d√©marr√©", id)

    for userID := range userIDs {
        if err := bp.processUser(userID); err != nil {
            log.Printf("Worker %d - Erreur traitement user %d: %v", id, userID, err)
        }
    }

    log.Printf("Worker %d termin√©", id)
}

func (bp *BatchProcessor) processUser(userID int) error {
    // Traitement avec transaction
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()

    tx, err := bp.db.BeginTx(ctx, nil)
    if err != nil {
        return err
    }
    defer tx.Rollback()

    // Simuler un traitement complexe
    _, err = tx.ExecContext(ctx,
        "UPDATE users SET status = 'processing', updated_at = NOW() WHERE id = $1",
        userID)
    if err != nil {
        return err
    }

    // Simulated work
    time.Sleep(100 * time.Millisecond)

    _, err = tx.ExecContext(ctx,
        "UPDATE users SET status = 'completed', updated_at = NOW() WHERE id = $1",
        userID)
    if err != nil {
        return err
    }

    return tx.Commit()
}
```

## Configuration finale recommand√©e

### Template de configuration universelle
```go
package config

import (
    "database/sql"
    "fmt"
    "os"
    "strconv"
    "time"
)

type DBConfig struct {
    MaxOpenConns    int
    MaxIdleConns    int
    ConnMaxLifetime time.Duration
    ConnMaxIdleTime time.Duration

    // Param√®tres de surveillance
    EnableMonitoring bool
    HealthCheckInterval time.Duration

    // Param√®tres de robustesse
    RetryAttempts int
    RetryDelay    time.Duration
}

func LoadDBConfig() DBConfig {
    return DBConfig{
        MaxOpenConns:        getEnvAsInt("DB_MAX_OPEN_CONNS", 25),
        MaxIdleConns:        getEnvAsInt("DB_MAX_IDLE_CONNS", 10),
        ConnMaxLifetime:     getEnvAsDuration("DB_CONN_MAX_LIFETIME", 5*time.Minute),
        ConnMaxIdleTime:     getEnvAsDuration("DB_CONN_MAX_IDLE_TIME", 1*time.Minute),
        EnableMonitoring:    getEnvAsBool("DB_ENABLE_MONITORING", true),
        HealthCheckInterval: getEnvAsDuration("DB_HEALTH_CHECK_INTERVAL", 30*time.Second),
        RetryAttempts:       getEnvAsInt("DB_RETRY_ATTEMPTS", 3),
        RetryDelay:          getEnvAsDuration("DB_RETRY_DELAY", 1*time.Second),
    }
}

func (config DBConfig) Apply(db *sql.DB) {
    db.SetMaxOpenConns(config.MaxOpenConns)
    db.SetMaxIdleConns(config.MaxIdleConns)
    db.SetConnMaxLifetime(config.ConnMaxLifetime)
    db.SetConnMaxIdleTime(config.ConnMaxIdleTime)

    if config.EnableMonitoring {
        go monitorPool(db, config.HealthCheckInterval)
    }
}

func getEnvAsInt(name string, defaultVal int) int {
    if val := os.Getenv(name); val != "" {
        if parsed, err := strconv.Atoi(val); err == nil {
            return parsed
        }
    }
    return defaultVal
}

func getEnvAsDuration(name string, defaultVal time.Duration) time.Duration {
    if val := os.Getenv(name); val != "" {
        if parsed, err := time.ParseDuration(val); err == nil {
            return parsed
        }
    }
    return defaultVal
}

func getEnvAsBool(name string, defaultVal bool) bool {
    if val := os.Getenv(name); val != "" {
        if parsed, err := strconv.ParseBool(val); err == nil {
            return parsed
        }
    }
    return defaultVal
}

func monitorPool(db *sql.DB, interval time.Duration) {
    ticker := time.NewTicker(interval)
    defer ticker.Stop()

    for range ticker.C {
        stats := db.Stats()

        // Logs de monitoring
        if stats.WaitCount > 0 {
            fmt.Printf("‚ö†Ô∏è  Pool pressure: %d waits, duration: %v\n",
                stats.WaitCount, stats.WaitDuration)
        }

        if stats.OpenConnections > stats.MaxOpenConnections*80/100 {
            fmt.Printf("‚ö†Ô∏è  Pool utilization high: %d/%d\n",
                stats.OpenConnections, stats.MaxOpenConnections)
        }
    }
}
```

## R√©sum√© et bonnes pratiques

### ‚úÖ √Ä faire
- **Configurer le pool** selon votre type d'application
- **Monitorer** les statistiques r√©guli√®rement
- **Utiliser des timeouts** avec Context
- **Fermer les ressources** avec defer
- **Tester sous charge** avant la production
- **Adapter la configuration** selon l'environnement

### ‚ùå √Ä √©viter
- Pool trop petit (goulot d'√©tranglement)
- Pool trop grand (surcharge de la BDD)
- Oublier de fermer les rows/statements
- Pas de timeout sur les requ√™tes
- Configuration identique pour tous les environnements

### üìä M√©triques importantes √† surveiller
- `OpenConnections` : Nombre de connexions actives
- `InUse` : Connexions en cours d'utilisation
- `WaitCount` : Nombre d'attentes de connexions
- `WaitDuration` : Temps d'attente total
- `MaxLifetimeClosed` : Connexions ferm√©es par expiration

### üéØ Valeurs recommand√©es par d√©faut
```go
// Configuration universelle
db.SetMaxOpenConns(25)
db.SetMaxIdleConns(10)
db.SetConnMaxLifetime(5 * time.Minute)
db.SetConnMaxIdleTime(1 * time.Minute)
```

Les pools de connexions sont essentiels pour des applications performantes et stables. Une bonne configuration peut faire la diff√©rence entre une application qui s'effondre sous la charge et une qui reste r√©active m√™me avec beaucoup d'utilisateurs simultan√©s.

Dans la prochaine section, nous explorerons les **patterns avanc√©s** et l'**architecture** pour construire des applications Go robustes avec des bases de donn√©es.

‚è≠Ô∏è
