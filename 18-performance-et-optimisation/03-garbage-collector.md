üîù Retour au [Sommaire](/SOMMAIRE.md)

# 18-3. Garbage collector

## Introduction

Le garbage collector (GC) de Go est comme un assistant invisible qui nettoie automatiquement la m√©moire de votre programme. Imaginez que vous cuisinez dans une cuisine : vous utilisez des ustensiles, des ingr√©dients, et vous cr√©ez des d√©chets. Le GC est comme quelqu'un qui passerait r√©guli√®rement pour nettoyer et ranger ce qui n'est plus utilis√©.

Comprendre le GC est crucial car il peut affecter les performances de votre application, surtout si vous cr√©ez beaucoup d'objets ou si vous avez besoin de tr√®s faibles latences.

## Qu'est-ce que le garbage collector ?

### D√©finition simple
Le garbage collector lib√®re automatiquement la m√©moire qui n'est plus utilis√©e par votre programme. Vous n'avez pas besoin d'appeler `free()` comme en C - Go s'en occupe pour vous !

### Pourquoi c'est important
```go
func createData() {
    data := make([]byte, 1024*1024) // 1MB d'allocation
    // Traitement des donn√©es...
    // √Ä la fin de la fonction, 'data' n'est plus accessible
    // Le GC va automatiquement lib√©rer cette m√©moire
}

func main() {
    for i := 0; i < 1000; i++ {
        createData() // Sans GC, on utiliserait 1GB de RAM !
    }
    // Gr√¢ce au GC, la m√©moire est r√©utilis√©e
}
```

## Comment fonctionne le GC de Go

### Le mod√®le tricolore (simplifi√©)

Le GC de Go utilise un algorithme "tricolore" qui classe les objets en trois cat√©gories :

1. **Blanc** : Objets potentiellement inutiles (candidats √† la suppression)
2. **Gris** : Objets en cours d'analyse
3. **Noir** : Objets confirm√©s comme encore utilis√©s

```go
// Exemple conceptuel
func demonstrateGC() {
    // Objet racine (toujours "noir" - jamais supprim√©)
    mainData := &Data{value: "important"}

    // Objet r√©f√©renc√© (devient "noir" pendant le GC)
    linkedData := &Data{value: "also important"}
    mainData.next = linkedData

    // Objet temporaire (devient "blanc" et sera supprim√©)
    tempData := &Data{value: "temporary"}
    _ = tempData // Plus de r√©f√©rence -> √©ligible pour le GC
}
```

### Phases du GC

1. **Mark** (Marquage) : Identifie quels objets sont encore utilis√©s
2. **Sweep** (Balayage) : Lib√®re les objets non marqu√©s
3. **Concurrent** : Ces op√©rations se font en parall√®le de votre programme

## Types de collecte en Go

### GC concurrent
Le GC de Go fonctionne en arri√®re-plan pendant que votre programme s'ex√©cute :

```go
func main() {
    for i := 0; i < 1000000; i++ {
        data := make([]int, 100)
        // Votre programme continue √† tourner
        // Le GC nettoie en parall√®le
        processData(data)
    }
}
```

### Avantages vs inconv√©nients

**Avantages :**
- Pas de pauses longues
- Votre programme reste r√©actif
- Gestion automatique de la m√©moire

**Inconv√©nients :**
- Utilise un peu de CPU pour le nettoyage
- Peut cr√©er de petites latences impr√©visibles

## Observer le comportement du GC

### Variables d'environnement utiles

```bash
# Affiche les statistiques du GC
export GODEBUG=gctrace=1
go run main.go

# Exemple de sortie :
# gc 1 @0.002s 0%: 0.018+1.3+0.076 ms clock, 0.074+0.35/1.2/3.0+0.30 ms cpu, 4->4->0 MB, 5 MB goal, 4 P
```

**Explication de la sortie :**
- `gc 1` : Premier cycle de GC
- `@0.002s` : Temps depuis le d√©marrage
- `0%` : Pourcentage de temps CPU utilis√© par le GC
- `4->4->0 MB` : M√©moire avant -> pendant -> apr√®s le GC

### Programme pour observer le GC

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func allocateMemory() {
    // Alloue beaucoup de petits objets
    var data [][]byte
    for i := 0; i < 10000; i++ {
        data = append(data, make([]byte, 1024))
    }
    // Les objets deviennent √©ligibles pour le GC √† la fin de la fonction
}

func printGCStats() {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    fmt.Printf("Allocs = %d KB", bToKb(m.Alloc))
    fmt.Printf(", TotalAllocs = %d KB", bToKb(m.TotalAlloc))
    fmt.Printf(", Sys = %d KB", bToKb(m.Sys))
    fmt.Printf(", NumGC = %d\n", m.NumGC)
}

func bToKb(b uint64) uint64 {
    return b / 1024
}

func main() {
    fmt.Println("Avant allocations:")
    printGCStats()

    // Alloue de la m√©moire
    for i := 0; i < 5; i++ {
        allocateMemory()
        fmt.Printf("Apr√®s allocation %d:\n", i+1)
        printGCStats()
        time.Sleep(100 * time.Millisecond)
    }

    // Force un garbage collection
    runtime.GC()
    fmt.Println("Apr√®s GC forc√©:")
    printGCStats()
}
```

## Optimiser pour le GC

### 1. R√©duire la pression sur le GC

```go
// ‚ùå Mauvais : Cr√©e beaucoup d'objets temporaires
func processDataBad(items []string) []string {
    var results []string
    for _, item := range items {
        // Allocation temporaire √† chaque it√©ration
        processed := strings.ToUpper(item)
        trimmed := strings.TrimSpace(processed)
        results = append(results, trimmed)
    }
    return results
}

// ‚úÖ Bon : R√©duit les allocations temporaires
func processDataGood(items []string) []string {
    results := make([]string, 0, len(items)) // Pr√©-alloue
    for _, item := range items {
        // Une seule allocation par √©tape
        processed := strings.TrimSpace(strings.ToUpper(item))
        results = append(results, processed)
    }
    return results
}
```

### 2. R√©utiliser les objets (Object Pooling)

```go
import "sync"

// Pool pour r√©utiliser les buffers
var bufferPool = sync.Pool{
    New: func() interface{} {
        // Cr√©e un nouveau buffer quand le pool est vide
        return make([]byte, 0, 1024)
    },
}

// ‚ùå Mauvais : Nouvelle allocation √† chaque appel
func formatDataBad(data []int) string {
    buffer := make([]byte, 0, 1024) // Allocation !
    for _, num := range data {
        buffer = append(buffer, []byte(fmt.Sprintf("%d,", num))...)
    }
    return string(buffer)
}

// ‚úÖ Bon : R√©utilise un buffer du pool
func formatDataGood(data []int) string {
    buffer := bufferPool.Get().([]byte)
    defer bufferPool.Put(buffer[:0]) // Remet dans le pool, capacit√© pr√©serv√©e

    for _, num := range data {
        buffer = append(buffer, []byte(fmt.Sprintf("%d,", num))...)
    }

    // Important : retourne une copie car le buffer sera r√©utilis√©
    return string(buffer)
}
```

### 3. Utiliser des structures plus efficaces

```go
// ‚ùå Mauvais : Beaucoup de petits objets
type NodeBad struct {
    Value string
    Next  *NodeBad // Pointeur = allocation s√©par√©e
}

// ‚úÖ Bon : Moins d'allocations avec des slices
type ListGood struct {
    Values []string // Tous les √©l√©ments dans un seul bloc m√©moire
}

func (l *ListGood) Add(value string) {
    l.Values = append(l.Values, value)
}
```

### 4. Contr√¥ler la fr√©quence du GC

```go
package main

import (
    "runtime"
    "runtime/debug"
)

func optimizeGCSettings() {
    // Ajuste le pourcentage cible pour le prochain GC
    // Plus √©lev√© = GC moins fr√©quent mais plus de m√©moire utilis√©e
    debug.SetGCPercent(200) // Par d√©faut : 100

    // Pour des applications avec beaucoup de m√©moire disponible
    // debug.SetGCPercent(500) // GC tr√®s peu fr√©quent

    // Pour des applications avec peu de m√©moire
    // debug.SetGCPercent(50) // GC plus fr√©quent
}

func main() {
    optimizeGCSettings()

    // Votre application...
}
```

## Patterns pour minimiser l'impact du GC

### 1. Batch processing

```go
// ‚ùå Mauvais : Traite un √©l√©ment √† la fois
func processItemsOneByOne(items []Data) {
    for _, item := range items {
        result := processItem(item) // Peut cr√©er des objets temporaires
        saveResult(result)
        // GC peut se d√©clencher √† chaque it√©ration
    }
}

// ‚úÖ Bon : Traite par lots
func processItemsBatch(items []Data) {
    const batchSize = 100

    for i := 0; i < len(items); i += batchSize {
        end := i + batchSize
        if end > len(items) {
            end = len(items)
        }

        batch := items[i:end]
        results := make([]Result, 0, len(batch))

        // Traite tout le lot d'un coup
        for _, item := range batch {
            results = append(results, processItem(item))
        }

        saveResults(results) // Sauvegarde par lot

        // Optionnel : force un GC entre les lots
        runtime.GC()
    }
}
```

### 2. Pr√©-allocation intelligente

```go
// ‚ùå Mauvais : Laisse le slice grandir dynamiquement
func collectResultsBad() []Result {
    var results []Result
    for i := 0; i < 10000; i++ {
        // Le slice va √™tre r√©allou√© plusieurs fois
        results = append(results, processData(i))
    }
    return results
}

// ‚úÖ Bon : Pr√©-alloue la taille finale
func collectResultsGood() []Result {
    results := make([]Result, 0, 10000) // Capacit√© connue √† l'avance
    for i := 0; i < 10000; i++ {
        results = append(results, processData(i))
    }
    return results
}
```

### 3. R√©utilisation de structures

```go
type DataProcessor struct {
    buffer    []byte     // R√©utilis√© pour chaque traitement
    tempSlice []int      // R√©utilis√© pour les calculs temporaires
    cache     map[string]Result // Cache pour √©viter les recalculs
}

func NewDataProcessor() *DataProcessor {
    return &DataProcessor{
        buffer:    make([]byte, 0, 1024),
        tempSlice: make([]int, 0, 100),
        cache:     make(map[string]Result),
    }
}

func (dp *DataProcessor) Process(data string) Result {
    // V√©rifie le cache d'abord
    if result, found := dp.cache[data]; found {
        return result
    }

    // R√©initialise les buffers sans r√©allouer
    dp.buffer = dp.buffer[:0]
    dp.tempSlice = dp.tempSlice[:0]

    // Utilise les buffers r√©utilisables
    dp.buffer = append(dp.buffer, []byte(data)...)

    // ... traitement ...

    result := Result{/* ... */}
    dp.cache[data] = result
    return result
}
```

## Mesurer l'impact du GC

### M√©triques importantes

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

type GCStats struct {
    NumGC        uint32
    PauseTotal   time.Duration
    LastPause    time.Duration
    AllocatedMB  uint64
}

func getGCStats() GCStats {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    return GCStats{
        NumGC:        m.NumGC,
        PauseTotal:   time.Duration(m.PauseTotalNs),
        LastPause:    time.Duration(m.PauseNs[(m.NumGC+255)%256]),
        AllocatedMB:  m.Alloc / 1024 / 1024,
    }
}

func monitorGC(duration time.Duration) {
    start := getGCStats()
    startTime := time.Now()

    time.Sleep(duration)

    end := getGCStats()
    elapsed := time.Since(startTime)

    fmt.Printf("P√©riode de monitoring: %v\n", elapsed)
    fmt.Printf("Cycles GC: %d\n", end.NumGC-start.NumGC)
    fmt.Printf("Temps total de pause: %v\n", end.PauseTotal-start.PauseTotal)
    fmt.Printf("Derni√®re pause: %v\n", end.LastPause)
    fmt.Printf("M√©moire allou√©e: %d MB\n", end.AllocatedMB)

    if end.NumGC > start.NumGC {
        avgPause := (end.PauseTotal - start.PauseTotal) / time.Duration(end.NumGC-start.NumGC)
        fmt.Printf("Pause moyenne: %v\n", avgPause)
    }
}
```

### Benchmark avec mesure GC

```go
func BenchmarkWithGCStats(b *testing.B) {
    var startGC, endGC runtime.MemStats

    // Mesure avant
    runtime.GC()
    runtime.ReadMemStats(&startGC)

    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        // Votre code √† benchmarker
        processData()
    }
    b.StopTimer()

    // Mesure apr√®s
    runtime.ReadMemStats(&endGC)

    // Rapporte les statistiques GC
    b.ReportMetric(float64(endGC.NumGC-startGC.NumGC), "gcs")
    b.ReportMetric(float64(endGC.TotalAlloc-startGC.TotalAlloc)/1024/1024, "MB-allocated")
}
```

## Cas d'usage sp√©cifiques

### Applications web avec faible latence

```go
func optimizeForWebServer() {
    // R√©duit la fr√©quence du GC pour √©viter les pauses pendant les requ√™tes
    debug.SetGCPercent(300)

    // Utilise des pools d'objets pour les structures communes
    var responsePool = sync.Pool{
        New: func() interface{} {
            return &Response{
                Headers: make(map[string]string),
                Body:    make([]byte, 0, 1024),
            }
        },
    }
}
```

### Applications de traitement de donn√©es

```go
func optimizeForDataProcessing() {
    // GC plus fr√©quent pour √©viter l'accumulation de m√©moire
    debug.SetGCPercent(50)

    // Force le GC apr√®s chaque lot de donn√©es
    func processBatch(data []Record) {
        // ... traitement ...
        runtime.GC() // Nettoie imm√©diatement
    }
}
```

### Applications en temps r√©el

```go
func optimizeForRealTime() {
    // Pr√©-alloue toute la m√©moire n√©cessaire au d√©marrage
    preallocateMemory()

    // D√©sactive temporairement le GC pendant les sections critiques
    func criticalSection() {
        debug.SetGCPercent(-1) // D√©sactive le GC
        defer debug.SetGCPercent(100) // R√©active apr√®s

        // Code critique qui ne doit pas √™tre interrompu
        performRealTimeTask()
    }
}
```

## Outils de debugging du GC

### 1. go tool trace

```go
func main() {
    f, err := os.Create("trace.out")
    if err != nil {
        panic(err)
    }
    defer f.Close()

    trace.Start(f)
    defer trace.Stop()

    // Votre code ici
    doWork()
}
```

```bash
go tool trace trace.out
```

### 2. Profiling m√©moire avec focus GC

```bash
# G√©n√®re un profil pendant que le GC est actif
go tool pprof http://localhost:6060/debug/pprof/allocs

# Dans pprof, analyser les allocations
(pprof) top10
(pprof) list main.functionName
```

## Bonnes pratiques r√©capitulatives

### Do's (√Ä faire)
- ‚úÖ Pr√©-allouer les slices et maps quand la taille est connue
- ‚úÖ R√©utiliser les objets avec des pools
- ‚úÖ Mesurer l'impact du GC sur votre application
- ‚úÖ Traiter les donn√©es par lots
- ‚úÖ Utiliser des buffers r√©utilisables

### Don'ts (√Ä √©viter)
- ‚ùå Cr√©er beaucoup de petits objets temporaires
- ‚ùå Forcer le GC trop souvent (sauf cas sp√©ciaux)
- ‚ùå Ignorer les m√©triques de GC en production
- ‚ùå Optimiser le GC sans mesurer l'impact r√©el
- ‚ùå D√©sactiver le GC sans tr√®s bonne raison

## Exercices pratiques

### Exercice 1 : Observer le GC

Cr√©ez un programme qui :
1. Alloue progressivement de la m√©moire
2. Affiche les statistiques GC √† intervalles r√©guliers
3. Observe comment le comportement change avec diff√©rents patterns d'allocation

### Exercice 2 : Optimiser une fonction

Optimisez cette fonction pour r√©duire la pression sur le GC :

```go
func processLogs(logs []string) map[string]int {
    counts := make(map[string]int)
    for _, log := range logs {
        parts := strings.Split(log, " ")
        if len(parts) > 0 {
            level := strings.ToUpper(strings.TrimSpace(parts[0]))
            counts[level]++
        }
    }
    return counts
}
```

**Indices :**
- Pr√©-allouer la map
- √âviter les allocations temporaires
- R√©utiliser des buffers

## R√©sum√©

Le garbage collector de Go est un outil puissant mais qu'il faut comprendre pour optimiser ses applications :

**Points cl√©s :**
- Le GC fonctionne en parall√®le de votre programme
- Il peut affecter les performances si mal g√©r√©
- L'objectif est de r√©duire la "pression" sur le GC

**Strat√©gies principales :**
- R√©duire les allocations temporaires
- R√©utiliser les objets avec des pools
- Pr√©-allouer quand c'est possible
- Mesurer l'impact r√©guli√®rement

**Outils de mesure :**
- Variables d'environnement `GODEBUG`
- Package `runtime` pour les m√©triques
- Profiling m√©moire avec `go tool pprof`

Dans le prochain chapitre, nous verrons comment d√©tecter et corriger les fuites m√©moire, un probl√®me qui peut court-circuiter l'efficacit√© du garbage collector.

‚è≠Ô∏è
