üîù Retour au [Sommaire](/SOMMAIRE.md)

# 18-4. Memory leaks (Fuites m√©moire)

## Introduction

Les fuites m√©moire en Go sont comme un robinet qui goutte : au d√©but, vous ne le remarquez pas, mais avec le temps, cela peut cr√©er de gros probl√®mes. M√™me si Go a un garbage collector, il ne peut pas nettoyer la m√©moire que votre programme garde "en vie" par accident.

Imaginez que vous gardez toutes vos factures dans une bo√Æte "au cas o√π". Au bout de 10 ans, votre maison est pleine de bo√Ætes de factures que vous n'utiliserez jamais. C'est exactement ce qui se passe avec les fuites m√©moire : votre programme garde des r√©f√©rences vers des donn√©es qu'il n'utilise plus.

## Qu'est-ce qu'une fuite m√©moire ?

### D√©finition simple
Une fuite m√©moire se produit quand votre programme alloue de la m√©moire mais ne la lib√®re jamais, m√™me quand elle n'est plus n√©cessaire.

### En Go vs autres langages
```go
// En C (gestion manuelle) - Fuite √©vidente
void memoryLeakC() {
    char* data = malloc(1024); // Alloue
    // Oublie d'appeler free(data) -> FUITE !
}

// En Go (avec GC) - Fuite plus subtile
func memoryLeakGo() {
    var globalSlice [][]byte // Slice global
    data := make([]byte, 1024)
    globalSlice = append(globalSlice, data) // R√©f√©rence gard√©e !
    // Le GC ne peut pas nettoyer car globalSlice r√©f√©rence encore data
}
```

### Pourquoi c'est dangereux
- **Consommation croissante de RAM** : Votre programme utilise de plus en plus de m√©moire
- **Performance d√©grad√©e** : Plus de m√©moire = plus de travail pour le GC
- **Crash possible** : Votre programme peut manquer de m√©moire
- **Co√ªts serveur** : Plus de RAM n√©cessaire en production

## Types de fuites m√©moire courantes

### 1. R√©f√©rences globales qui s'accumulent

```go
// ‚ùå FUITE : Slice global qui grandit ind√©finiment
var globalCache []ExpensiveData

func processData(input string) {
    data := ExpensiveData{
        Content: input,
        Buffer:  make([]byte, 1024*1024), // 1MB par objet !
    }

    // Ajoute √† un cache global qui n'est jamais nettoy√©
    globalCache = append(globalCache, data)

    // M√™me si 'data' n'est plus utilis√© dans cette fonction,
    // il reste en vie via globalCache
}

// ‚úÖ SOLUTION : Cache avec limite de taille
type SafeCache struct {
    data []ExpensiveData
    maxSize int
}

func (c *SafeCache) Add(item ExpensiveData) {
    c.data = append(c.data, item)

    // Nettoie les anciens √©l√©ments
    if len(c.data) > c.maxSize {
        // Garde seulement les plus r√©cents
        copy(c.data, c.data[len(c.data)-c.maxSize:])
        c.data = c.data[:c.maxSize]
    }
}
```

### 2. Goroutines qui ne se terminent jamais

```go
// ‚ùå FUITE : Goroutine qui boucle ind√©finiment
func startWorkerWithLeak() {
    data := make([]byte, 1024*1024) // 1MB

    go func() {
        for {
            // Boucle infinie sans condition de sortie !
            // 'data' reste accessible donc ne peut pas √™tre collect√©
            processBuffer(data)
            time.Sleep(time.Second)
        }
    }() // Cette goroutine ne se termine jamais
}

// ‚úÖ SOLUTION : Goroutine avec condition de sortie
func startWorkerSafe(ctx context.Context) {
    data := make([]byte, 1024*1024)

    go func() {
        for {
            select {
            case <-ctx.Done():
                // Condition de sortie propre
                return // La goroutine se termine, 'data' peut √™tre collect√©
            default:
                processBuffer(data)
                time.Sleep(time.Second)
            }
        }
    }()
}

// Usage
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    startWorkerSafe(ctx)

    // Plus tard...
    cancel() // Arr√™te proprement la goroutine
}
```

### 3. Closures qui capturent de gros objets

```go
// ‚ùå FUITE : Closure capture plus que n√©cessaire
func createHandlersWithLeak() []func() {
    largeData := make([]byte, 1024*1024*100) // 100MB !

    var handlers []func()

    for i := 0; i < 1000; i++ {
        index := i
        handler := func() {
            // Cette closure capture toute la variable largeData
            // m√™me si elle n'utilise que l'index !
            fmt.Printf("Handler %d with large data size: %d\n",
                      index, len(largeData))
        }
        handlers = append(handlers, handler)
    }

    // largeData ne peut pas √™tre collect√© car toutes les closures
    // y font r√©f√©rence !
    return handlers
}

// ‚úÖ SOLUTION : Capture seulement ce qui est n√©cessaire
func createHandlersSafe() []func() {
    largeData := make([]byte, 1024*1024*100)
    dataSize := len(largeData) // Capture seulement la taille

    // largeData peut maintenant √™tre collect√©
    largeData = nil

    var handlers []func()

    for i := 0; i < 1000; i++ {
        index := i
        handler := func() {
            // Capture seulement les variables n√©cessaires
            fmt.Printf("Handler %d with data size: %d\n", index, dataSize)
        }
        handlers = append(handlers, handler)
    }

    return handlers
}
```

### 4. Maps qui ne sont jamais nettoy√©es

```go
// ‚ùå FUITE : Map qui grandit ind√©finiment
type UserSession struct {
    sessions map[string]*SessionData
    mutex    sync.RWMutex
}

func (us *UserSession) CreateSession(userID string) {
    us.mutex.Lock()
    defer us.mutex.Unlock()

    us.sessions[userID] = &SessionData{
        Created: time.Now(),
        Data:    make([]byte, 1024*1024), // 1MB par session
    }
    // Probl√®me : les sessions ne sont jamais supprim√©es !
}

// ‚úÖ SOLUTION : Nettoyage p√©riodique
type SafeUserSession struct {
    sessions map[string]*SessionData
    mutex    sync.RWMutex
}

func (us *SafeUserSession) CreateSession(userID string) {
    us.mutex.Lock()
    defer us.mutex.Unlock()

    us.sessions[userID] = &SessionData{
        Created: time.Now(),
        Data:    make([]byte, 1024*1024),
    }
}

func (us *SafeUserSession) CleanupExpiredSessions() {
    us.mutex.Lock()
    defer us.mutex.Unlock()

    now := time.Now()
    for userID, session := range us.sessions {
        // Supprime les sessions de plus d'1 heure
        if now.Sub(session.Created) > time.Hour {
            delete(us.sessions, userID)
        }
    }
}

// D√©marre un nettoyage p√©riodique
func (us *SafeUserSession) StartCleanupRoutine(ctx context.Context) {
    ticker := time.NewTicker(10 * time.Minute)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            us.CleanupExpiredSessions()
        }
    }
}
```

### 5. Slices qui gardent des r√©f√©rences vers de gros tableaux

```go
// ‚ùå FUITE : Slice garde une r√©f√©rence vers un gros tableau
func processLargeDataWithLeak() []byte {
    // Gros tableau de 100MB
    largeArray := make([]byte, 1024*1024*100)

    // Remplit avec des donn√©es
    for i := range largeArray {
        largeArray[i] = byte(i % 256)
    }

    // On veut juste garder les 1000 premiers bytes
    result := largeArray[:1000]

    // PROBL√àME : result garde une r√©f√©rence vers tout largeArray !
    // Les 100MB ne peuvent pas √™tre collect√©s
    return result
}

// ‚úÖ SOLUTION : Copie explicite
func processLargeDataSafe() []byte {
    largeArray := make([]byte, 1024*1024*100)

    for i := range largeArray {
        largeArray[i] = byte(i % 256)
    }

    // Copie explicite pour casser la r√©f√©rence
    result := make([]byte, 1000)
    copy(result, largeArray[:1000])

    // largeArray peut maintenant √™tre collect√©
    return result
}
```

## D√©tecter les fuites m√©moire

### 1. Surveillance basique avec runtime

```go
package main

import (
    "fmt"
    "runtime"
    "time"
)

func monitorMemory() {
    ticker := time.NewTicker(5 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            var m runtime.MemStats
            runtime.ReadMemStats(&m)

            fmt.Printf("Alloc = %d KB", m.Alloc/1024)
            fmt.Printf(", TotalAlloc = %d KB", m.TotalAlloc/1024)
            fmt.Printf(", Sys = %d KB", m.Sys/1024)
            fmt.Printf(", NumGC = %d", m.NumGC)
            fmt.Printf(", Goroutines = %d\n", runtime.NumGoroutine())

            // Signe d'alerte : m√©moire qui augmente constamment
            if m.Alloc/1024 > 500*1024 { // Plus de 500MB
                fmt.Println("‚ö†Ô∏è ALERTE : Consommation m√©moire √©lev√©e !")
            }
        }
    }
}

func main() {
    go monitorMemory()

    // Simule une fuite m√©moire
    simulateMemoryLeak()
}

func simulateMemoryLeak() {
    var leakySlice [][]byte

    for i := 0; i < 1000; i++ {
        // Ajoute 1MB √† chaque it√©ration
        data := make([]byte, 1024*1024)
        leakySlice = append(leakySlice, data)

        time.Sleep(100 * time.Millisecond)

        // Les donn√©es s'accumulent et ne sont jamais lib√©r√©es !
    }
}
```

### 2. Profiling m√©moire avanc√©

```go
// Programme pour analyser les fuites
package main

import (
    "log"
    "net/http"
    _ "net/http/pprof"
    "time"
)

func main() {
    // Active le serveur de profiling
    go func() {
        log.Println("Serveur pprof sur :6060")
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()

    // Simule une application avec une fuite
    go simulateApplicationWithLeak()

    // Garde le programme en vie
    select {}
}

func simulateApplicationWithLeak() {
    var globalData [][]byte

    ticker := time.NewTicker(1 * time.Second)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            // Simule du travail qui cr√©e une fuite
            data := make([]byte, 1024*1024) // 1MB
            globalData = append(globalData, data)

            // Simule un "nettoyage" insuffisant
            if len(globalData) > 100 {
                // Ne supprime que le premier √©l√©ment au lieu de faire un vrai nettoyage
                globalData = globalData[1:]
            }
        }
    }
}
```

```bash
# Analyser la fuite m√©moire
go run main.go

# Dans un autre terminal, analyser le profil m√©moire
go tool pprof http://localhost:6060/debug/pprof/heap

# Dans pprof
(pprof) top10
(pprof) list main.simulateApplicationWithLeak
(pprof) web  # Visualisation graphique
```

### 3. Tests automatiques pour d√©tecter les fuites

```go
func TestNoMemoryLeak(t *testing.T) {
    // Mesure la m√©moire avant
    runtime.GC()
    var m1 runtime.MemStats
    runtime.ReadMemStats(&m1)

    // Ex√©cute la fonction suspecte plusieurs fois
    for i := 0; i < 1000; i++ {
        functionToTest()
    }

    // Force un garbage collection
    runtime.GC()
    runtime.GC() // Double GC pour √™tre s√ªr

    // Mesure la m√©moire apr√®s
    var m2 runtime.MemStats
    runtime.ReadMemStats(&m2)

    // V√©rifie qu'il n'y a pas de fuite significative
    memoryIncrease := m2.Alloc - m1.Alloc
    maxAcceptableIncrease := uint64(1024 * 1024) // 1MB max

    if memoryIncrease > maxAcceptableIncrease {
        t.Errorf("Possible fuite m√©moire d√©tect√©e: %d bytes",
                 memoryIncrease)
    }
}

func BenchmarkMemoryUsage(b *testing.B) {
    b.ReportAllocs() // Affiche les allocations

    for i := 0; i < b.N; i++ {
        functionToTest()
    }

    // Si allocs/op augmente √† chaque run, il y a probablement une fuite
}
```

## Corriger les fuites m√©moire

### 1. Pattern Context pour les goroutines

```go
type WorkerManager struct {
    workers []Worker
    ctx     context.Context
    cancel  context.CancelFunc
}

func NewWorkerManager() *WorkerManager {
    ctx, cancel := context.WithCancel(context.Background())
    return &WorkerManager{
        ctx:    ctx,
        cancel: cancel,
    }
}

func (wm *WorkerManager) StartWorker(id int) {
    worker := Worker{
        ID:   id,
        data: make([]byte, 1024*1024), // Donn√©es par worker
    }

    go func() {
        defer func() {
            // Nettoyage automatique quand la goroutine se termine
            worker.data = nil
        }()

        ticker := time.NewTicker(time.Second)
        defer ticker.Stop()

        for {
            select {
            case <-wm.ctx.Done():
                // Sortie propre
                return
            case <-ticker.C:
                worker.DoWork()
            }
        }
    }()

    wm.workers = append(wm.workers, worker)
}

func (wm *WorkerManager) Shutdown() {
    wm.cancel() // Arr√™te toutes les goroutines
    // Toutes les donn√©es des workers seront lib√©r√©es
}
```

### 2. Pattern Reference Counting

```go
type SharedResource struct {
    data     []byte
    refCount int32
    mutex    sync.Mutex
}

func NewSharedResource() *SharedResource {
    return &SharedResource{
        data:     make([]byte, 1024*1024),
        refCount: 1, // Compteur initial
    }
}

func (sr *SharedResource) AddRef() {
    atomic.AddInt32(&sr.refCount, 1)
}

func (sr *SharedResource) Release() {
    if atomic.AddInt32(&sr.refCount, -1) == 0 {
        // Plus de r√©f√©rences, lib√®re la m√©moire
        sr.mutex.Lock()
        sr.data = nil
        sr.mutex.Unlock()
    }
}

func (sr *SharedResource) GetData() []byte {
    sr.mutex.Lock()
    defer sr.mutex.Unlock()
    return sr.data
}
```

### 3. Pattern Weak References (simulation)

```go
type WeakRef struct {
    target interface{}
    valid  bool
    mutex  sync.RWMutex
}

func NewWeakRef(target interface{}) *WeakRef {
    return &WeakRef{
        target: target,
        valid:  true,
    }
}

func (wr *WeakRef) Get() interface{} {
    wr.mutex.RLock()
    defer wr.mutex.RUnlock()

    if wr.valid {
        return wr.target
    }
    return nil
}

func (wr *WeakRef) Invalidate() {
    wr.mutex.Lock()
    defer wr.mutex.Unlock()

    wr.target = nil
    wr.valid = false
}

// Usage dans un cache avec weak references
type WeakCache struct {
    items map[string]*WeakRef
    mutex sync.RWMutex
}

func (wc *WeakCache) Set(key string, value interface{}) {
    wc.mutex.Lock()
    defer wc.mutex.Unlock()

    wc.items[key] = NewWeakRef(value)
}

func (wc *WeakCache) Get(key string) interface{} {
    wc.mutex.RLock()
    defer wc.mutex.RUnlock()

    if ref, exists := wc.items[key]; exists {
        return ref.Get()
    }
    return nil
}
```

## Outils de d√©tection automatique

### 1. Script de monitoring

```bash
#!/bin/bash
# monitor_memory.sh

echo "Monitoring de la m√©moire pour le processus Go"
while true; do
    # Trouve le PID du processus Go
    PID=$(pgrep -f "your-go-app")

    if [ ! -z "$PID" ]; then
        # Mesure l'utilisation m√©moire
        MEMORY=$(ps -o pid,vsz,rss,comm -p $PID | tail -1)
        echo "$(date): $MEMORY"

        # Alerte si plus de 1GB
        RSS=$(echo $MEMORY | awk '{print $3}')
        if [ $RSS -gt 1048576 ]; then
            echo "‚ö†Ô∏è ALERTE: Consommation m√©moire √©lev√©e: ${RSS}KB"
        fi
    fi

    sleep 5
done
```

### 2. Middleware de surveillance HTTP

```go
func memoryMonitoringMiddleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Mesure avant
        var m1 runtime.MemStats
        runtime.ReadMemStats(&m1)

        start := time.Now()
        next.ServeHTTP(w, r)
        duration := time.Since(start)

        // Mesure apr√®s
        var m2 runtime.MemStats
        runtime.ReadMemStats(&m2)

        // Log si augmentation significative
        memIncrease := m2.Alloc - m1.Alloc
        if memIncrease > 1024*1024 { // Plus de 1MB
            log.Printf("‚ö†Ô∏è Requ√™te %s a allou√© %d KB en %v",
                      r.URL.Path, memIncrease/1024, duration)
        }
    })
}
```

## Exemples de fuites r√©elles et leurs corrections

### Exemple 1 : Fuite dans un serveur HTTP

```go
// ‚ùå PROBL√àME : Accumulation des connexions
type Server struct {
    connections map[string]*Connection
    mutex       sync.RWMutex
}

func (s *Server) HandleConnection(id string, conn *Connection) {
    s.mutex.Lock()
    s.connections[id] = conn
    s.mutex.Unlock()

    // PROBL√àME : Connexion jamais supprim√©e de la map !
}

// ‚úÖ SOLUTION : Nettoyage automatique
type SafeServer struct {
    connections map[string]*Connection
    mutex       sync.RWMutex
    cleanup     chan string
}

func NewSafeServer() *SafeServer {
    s := &SafeServer{
        connections: make(map[string]*Connection),
        cleanup:     make(chan string, 100),
    }

    // Goroutine de nettoyage
    go s.cleanupRoutine()
    return s
}

func (s *SafeServer) HandleConnection(id string, conn *Connection) {
    s.mutex.Lock()
    s.connections[id] = conn
    s.mutex.Unlock()

    // Nettoie automatiquement quand la connexion se ferme
    go func() {
        <-conn.Done() // Attend que la connexion se ferme
        s.cleanup <- id
    }()
}

func (s *SafeServer) cleanupRoutine() {
    for id := range s.cleanup {
        s.mutex.Lock()
        delete(s.connections, id)
        s.mutex.Unlock()
    }
}
```

### Exemple 2 : Fuite dans un cache LRU

```go
// ‚úÖ Impl√©mentation correcte d'un cache LRU sans fuite
type LRUCache struct {
    capacity int
    items    map[string]*Item
    order    *list.List
    mutex    sync.RWMutex
}

type Item struct {
    key   string
    value interface{}
    elem  *list.Element
}

func NewLRUCache(capacity int) *LRUCache {
    return &LRUCache{
        capacity: capacity,
        items:    make(map[string]*Item),
        order:    list.New(),
    }
}

func (c *LRUCache) Set(key string, value interface{}) {
    c.mutex.Lock()
    defer c.mutex.Unlock()

    if item, exists := c.items[key]; exists {
        // Met √† jour l'√©l√©ment existant
        item.value = value
        c.order.MoveToFront(item.elem)
        return
    }

    // Nouvel √©l√©ment
    item := &Item{
        key:   key,
        value: value,
    }
    item.elem = c.order.PushFront(item)
    c.items[key] = item

    // √âviction si n√©cessaire (√©vite la fuite)
    if c.order.Len() > c.capacity {
        c.evictOldest()
    }
}

func (c *LRUCache) evictOldest() {
    elem := c.order.Back()
    if elem != nil {
        item := elem.Value.(*Item)
        delete(c.items, item.key)
        c.order.Remove(elem)
    }
}
```

## Checklist anti-fuite m√©moire

### Avant de coder
- [ ] D√©finir clairement le cycle de vie des objets
- [ ] Pr√©voir les m√©canismes de nettoyage
- [ ] Identifier les r√©f√©rences globales n√©cessaires

### Pendant le d√©veloppement
- [ ] Utiliser context.Context pour les goroutines
- [ ] Limiter la taille des caches et collections
- [ ] √âviter les closures qui capturent de gros objets
- [ ] Impl√©menter des m√©canismes de nettoyage p√©riodique

### Tests et monitoring
- [ ] √âcrire des tests de non-r√©gression m√©moire
- [ ] Surveiller l'utilisation m√©moire en continu
- [ ] Profiler r√©guli√®rement l'application
- [ ] Mettre en place des alertes sur la consommation m√©moire

## Exercices pratiques

### Exercice 1 : D√©tecter la fuite

Trouvez et corrigez la fuite dans ce code :

```go
type EventLogger struct {
    events []Event
}

func (el *EventLogger) LogEvent(event Event) {
    el.events = append(el.events, event)
    // Traite l'√©v√©nement...
}

func (el *EventLogger) ProcessEvents() {
    for _, event := range el.events {
        handleEvent(event)
    }
    // O√π est le probl√®me ?
}
```

### Exercice 2 : Optimiser un worker pool

Corrigez cette impl√©mentation qui fuit de la m√©moire :

```go
func ProcessJobs(jobs []Job) {
    for _, job := range jobs {
        go func(j Job) {
            result := processJob(j)
            // Stocke le r√©sultat quelque part...
            storeResult(result)
        }(job)
    }
}
```

## R√©sum√©

Les fuites m√©moire en Go sont souvent caus√©es par :

**Causes principales :**
- R√©f√©rences globales qui s'accumulent
- Goroutines qui ne se terminent jamais
- Closures qui capturent trop de donn√©es
- Collections qui ne sont jamais nettoy√©es

**Strat√©gies de pr√©vention :**
- Utiliser context.Context pour contr√¥ler le cycle de vie
- Impl√©menter des m√©canismes de nettoyage
- Limiter la taille des caches et collections
- Tester r√©guli√®rement la consommation m√©moire

**Outils de d√©tection :**
- Monitoring avec le package runtime
- Profiling avec go tool pprof
- Tests automatiques de non-r√©gression

**Principe fondamental :** Chaque allocation doit avoir un chemin vers la lib√©ration !

La gestion proactive des fuites m√©moire est essentielle pour maintenir des applications Go performantes et stables en production.

‚è≠Ô∏è
