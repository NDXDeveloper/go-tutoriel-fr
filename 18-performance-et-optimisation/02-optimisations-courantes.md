üîù Retour au [Sommaire](/SOMMAIRE.md)

# 18-2. Optimisations courantes

## Introduction

Maintenant que vous savez utiliser le profiling pour identifier les probl√®mes de performance, apprenons les techniques d'optimisation les plus courantes en Go. Ces optimisations sont comme des "recettes" que vous pouvez appliquer dans vos programmes.

Pensez √† ces optimisations comme √† des conseils pour conduire de mani√®re plus √©conomique : √©viter les freinages brusques, maintenir une vitesse constante, bien gonfler les pneus... Chaque petite am√©lioration contribue √† un meilleur r√©sultat global.

## Principe g√©n√©ral : Optimiser intelligemment

### La r√®gle des 80/20
80% des probl√®mes de performance viennent de 20% du code. Concentrez-vous sur les parties qui comptent vraiment !

### Ordre d'optimisation (par impact)
1. **Algorithmes** : Choisir le bon algorithme (O(n) vs O(n¬≤))
2. **Structures de donn√©es** : Utiliser les bonnes structures
3. **Allocations m√©moire** : R√©duire les allocations inutiles
4. **I/O** : Optimiser les lectures/√©critures
5. **Micro-optimisations** : Petites am√©liorations de code

## 1. Optimisations algorithmiques

### Choisir la bonne complexit√©

```go
// ‚ùå Mauvais : O(n¬≤) - Lent pour de grandes donn√©es
func findDuplicatesSlow(data []string) []string {
    var duplicates []string
    for i := 0; i < len(data); i++ {
        for j := i + 1; j < len(data); j++ {
            if data[i] == data[j] {
                duplicates = append(duplicates, data[i])
                break
            }
        }
    }
    return duplicates
}

// ‚úÖ Bon : O(n) - Rapide m√™me avec beaucoup de donn√©es
func findDuplicatesFast(data []string) []string {
    seen := make(map[string]bool)
    var duplicates []string

    for _, item := range data {
        if seen[item] {
            duplicates = append(duplicates, item)
        } else {
            seen[item] = true
        }
    }
    return duplicates
}
```

### √âviter les calculs redondants

```go
// ‚ùå Mauvais : Calcule la longueur √† chaque it√©ration
func processItemsSlow(items []string) {
    for i := 0; i < len(items); i++ { // len(items) appel√© √† chaque fois !
        fmt.Println(items[i])
    }
}

// ‚úÖ Bon : Calcule la longueur une seule fois
func processItemsFast(items []string) {
    length := len(items) // Calcul√© une seule fois
    for i := 0; i < length; i++ {
        fmt.Println(items[i])
    }
}

// ‚úÖ Encore mieux : Utilise range (plus idiomatique en Go)
func processItemsBest(items []string) {
    for _, item := range items {
        fmt.Println(item)
    }
}
```

## 2. Optimisations des structures de donn√©es

### Choisir la bonne structure

```go
// Pour chercher des √©l√©ments
type UserStore struct {
    // ‚ùå Mauvais : Recherche O(n)
    users []User

    // ‚úÖ Bon : Recherche O(1)
    usersByID map[int]User
    usersByEmail map[string]User
}

// Pour des donn√©es ordonn√©es
// ‚ùå Mauvais : Tri √† chaque recherche
func findInSlice(data []int, target int) bool {
    sort.Ints(data) // Tri co√ªteux !
    i := sort.SearchInts(data, target)
    return i < len(data) && data[i] == target
}

// ‚úÖ Bon : Tri une seule fois
type SortedData struct {
    data []int
    sorted bool
}

func (s *SortedData) Add(value int) {
    s.data = append(s.data, value)
    s.sorted = false
}

func (s *SortedData) Contains(target int) bool {
    if !s.sorted {
        sort.Ints(s.data)
        s.sorted = true
    }
    i := sort.SearchInts(s.data, target)
    return i < len(s.data) && s.data[i] == target
}
```

### Pr√©-allouer les slices

```go
// ‚ùå Mauvais : R√©allocations multiples
func createNumbersSlow(n int) []int {
    var numbers []int
    for i := 0; i < n; i++ {
        numbers = append(numbers, i) // R√©allocation possible √† chaque append !
    }
    return numbers
}

// ‚úÖ Bon : Allocation unique
func createNumbersFast(n int) []int {
    numbers := make([]int, 0, n) // Pr√©-alloue la capacit√©
    for i := 0; i < n; i++ {
        numbers = append(numbers, i)
    }
    return numbers
}

// ‚úÖ Encore mieux : Utilise l'index directement
func createNumbersBest(n int) []int {
    numbers := make([]int, n) // Pr√©-alloue la taille
    for i := 0; i < n; i++ {
        numbers[i] = i
    }
    return numbers
}
```

## 3. Optimisations m√©moire

### R√©utiliser les objets (Object Pooling)

```go
import "sync"

// Pool d'objets pour √©viter les allocations r√©p√©t√©es
var bufferPool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 0, 1024) // Buffer de 1KB
    },
}

// ‚ùå Mauvais : Allocation √† chaque appel
func processDataSlow(data []byte) []byte {
    buffer := make([]byte, len(data)*2) // Nouvelle allocation !
    copy(buffer, data)
    // ... traitement
    return buffer
}

// ‚úÖ Bon : R√©utilise un buffer du pool
func processDataFast(data []byte) []byte {
    buffer := bufferPool.Get().([]byte)
    defer bufferPool.Put(buffer[:0]) // Remet dans le pool

    // S'assure que le buffer est assez grand
    if cap(buffer) < len(data)*2 {
        buffer = make([]byte, 0, len(data)*2)
    }

    buffer = buffer[:len(data)*2]
    copy(buffer, data)
    // ... traitement

    // Retourne une copie car le buffer sera r√©utilis√©
    result := make([]byte, len(buffer))
    copy(result, buffer)
    return result
}
```

### Optimiser les conversions de cha√Ænes

```go
// ‚ùå Mauvais : Conversions r√©p√©t√©es
func buildURLSlow(parts []string) string {
    var result string
    for _, part := range parts {
        result += "/" + part // Allocation √† chaque concat√©nation !
    }
    return result
}

// ‚úÖ Bon : Utilise strings.Builder
func buildURLFast(parts []string) string {
    var builder strings.Builder

    // Estime la taille finale pour √©viter les r√©allocations
    totalSize := len(parts) // Pour les "/"
    for _, part := range parts {
        totalSize += len(part)
    }
    builder.Grow(totalSize)

    for _, part := range parts {
        builder.WriteString("/")
        builder.WriteString(part)
    }
    return builder.String()
}

// ‚úÖ Alternative : Utilise strings.Join
func buildURLBest(parts []string) string {
    return "/" + strings.Join(parts, "/")
}
```

### √âviter les conversions inutiles

```go
// ‚ùå Mauvais : Conversions r√©p√©t√©es
func processNumbersSlow(numbers []string) int {
    sum := 0
    for _, numStr := range numbers {
        num, err := strconv.Atoi(numStr)
        if err != nil {
            continue
        }
        // Conversion inutile pour la comparaison
        if strconv.Itoa(num) == numStr {
            sum += num
        }
    }
    return sum
}

// ‚úÖ Bon : √âvite les conversions inutiles
func processNumbersFast(numbers []string) int {
    sum := 0
    for _, numStr := range numbers {
        num, err := strconv.Atoi(numStr)
        if err != nil {
            continue
        }
        // Pas besoin de reconvertir !
        sum += num
    }
    return sum
}
```

## 4. Optimisations I/O

### Utiliser le buffering

```go
// ‚ùå Mauvais : √âcrit ligne par ligne
func writeLinesSlow(filename string, lines []string) error {
    file, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer file.Close()

    for _, line := range lines {
        _, err := file.WriteString(line + "\n") // Appel syst√®me √† chaque ligne !
        if err != nil {
            return err
        }
    }
    return nil
}

// ‚úÖ Bon : Utilise un buffer
func writeLinesFast(filename string, lines []string) error {
    file, err := os.Create(filename)
    if err != nil {
        return err
    }
    defer file.Close()

    writer := bufio.NewWriter(file)
    defer writer.Flush()

    for _, line := range lines {
        _, err := writer.WriteString(line + "\n") // √âcrit dans le buffer
        if err != nil {
            return err
        }
    }
    return nil
}
```

### Lire par chunks

```go
// ‚ùå Mauvais : Lit tout en m√©moire
func processLargeFileSlow(filename string) error {
    data, err := os.ReadFile(filename) // Charge tout le fichier !
    if err != nil {
        return err
    }

    // Traite toutes les donn√©es
    for _, b := range data {
        // ... traitement
        _ = b
    }
    return nil
}

// ‚úÖ Bon : Lit par chunks
func processLargeFileFast(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()

    reader := bufio.NewReader(file)
    buffer := make([]byte, 4096) // Buffer de 4KB

    for {
        n, err := reader.Read(buffer)
        if err != nil && err != io.EOF {
            return err
        }
        if n == 0 {
            break
        }

        // Traite seulement les donn√©es lues
        for i := 0; i < n; i++ {
            // ... traitement
            _ = buffer[i]
        }
    }
    return nil
}
```

## 5. Optimisations de concurrence

### Utiliser des worker pools

```go
// ‚ùå Mauvais : Cr√©e une goroutine par t√¢che
func processTasksSlow(tasks []Task) {
    var wg sync.WaitGroup

    for _, task := range tasks {
        wg.Add(1)
        go func(t Task) { // Peut cr√©er des milliers de goroutines !
            defer wg.Done()
            t.Process()
        }(task)
    }

    wg.Wait()
}

// ‚úÖ Bon : Utilise un pool de workers
func processTasksFast(tasks []Task) {
    const numWorkers = 10
    taskChan := make(chan Task, len(tasks))
    var wg sync.WaitGroup

    // D√©marre les workers
    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for task := range taskChan {
                task.Process()
            }
        }()
    }

    // Envoie les t√¢ches
    for _, task := range tasks {
        taskChan <- task
    }
    close(taskChan)

    wg.Wait()
}
```

### √âviter la contention sur les mutex

```go
// ‚ùå Mauvais : Mutex global pour tout
type CounterSlow struct {
    mu    sync.Mutex
    count int
    data  map[string]int
}

func (c *CounterSlow) Increment() {
    c.mu.Lock()
    defer c.mu.Unlock()
    c.count++
}

func (c *CounterSlow) Get(key string) int {
    c.mu.Lock()
    defer c.mu.Unlock()
    return c.data[key] // M√™me mutex pour des donn√©es diff√©rentes !
}

// ‚úÖ Bon : Mutex s√©par√©s
type CounterFast struct {
    countMu sync.Mutex
    count   int

    dataMu sync.RWMutex
    data   map[string]int
}

func (c *CounterFast) Increment() {
    c.countMu.Lock()
    defer c.countMu.Unlock()
    c.count++
}

func (c *CounterFast) Get(key string) int {
    c.dataMu.RLock() // Lecture concurrente possible
    defer c.dataMu.RUnlock()
    return c.data[key]
}
```

## 6. Optimisations de compilation

### Utiliser les build tags pour les optimisations

```go
// +build optimize

// optimized.go - Version optimis√©e
func expensiveOperation() {
    // Version optimis√©e mais plus complexe
}
```

```go
// +build !optimize

// normal.go - Version normale
func expensiveOperation() {
    // Version simple mais moins optimis√©e
}
```

```bash
# Compilation avec optimisations
go build -tags optimize

# Compilation normale
go build
```

### Optimisations du compilateur

```bash
# D√©sactiver les v√©rifications de bounds (dangereux !)
go build -gcflags=-B

# Optimisations agressives
go build -ldflags="-s -w"
```

## 7. Micro-optimisations

### √âviter les allocations dans les boucles

```go
// ‚ùå Mauvais : Allocation dans la boucle
func processItemsSlow(items []string) {
    for _, item := range items {
        parts := strings.Split(item, ",") // Allocation √† chaque it√©ration !
        // ... traitement
        _ = parts
    }
}

// ‚úÖ Bon : R√©utilise le slice
func processItemsFast(items []string) {
    var parts []string
    for _, item := range items {
        parts = parts[:0] // R√©initialise sans allouer
        parts = strings.Split(item, ",")
        // ... traitement
        _ = parts
    }
}
```

### Utiliser les types appropri√©s

```go
// ‚ùå Mauvais : Interface vide co√ªteuse
func processValuesSlow(values []interface{}) {
    for _, v := range values {
        // Type assertion co√ªteuse
        if str, ok := v.(string); ok {
            fmt.Println(str)
        }
    }
}

// ‚úÖ Bon : Type sp√©cifique
func processValuesFast(values []string) {
    for _, v := range values {
        fmt.Println(v) // Pas d'assertion de type
    }
}
```

## 8. Exemple complet d'optimisation

### Probl√®me : Analyser un fichier de logs

```go
// ‚ùå Version lente
func analyzeLogsSlow(filename string) (map[string]int, error) {
    // Lit tout le fichier
    data, err := os.ReadFile(filename)
    if err != nil {
        return nil, err
    }

    lines := strings.Split(string(data), "\n")
    results := make(map[string]int)

    for _, line := range lines {
        // Parsing co√ªteux
        parts := strings.Split(line, " ")
        if len(parts) > 0 {
            // Conversion co√ªteuse
            key := strings.ToLower(strings.TrimSpace(parts[0]))
            results[key]++
        }
    }

    return results, nil
}

// ‚úÖ Version optimis√©e
func analyzeLogsFast(filename string) (map[string]int, error) {
    file, err := os.Open(filename)
    if err != nil {
        return nil, err
    }
    defer file.Close()

    // Estime la taille de la map
    results := make(map[string]int, 1000)

    scanner := bufio.NewScanner(file)
    // Buffer plus grand pour les longues lignes
    buffer := make([]byte, 64*1024)
    scanner.Buffer(buffer, 1024*1024)

    for scanner.Scan() {
        line := scanner.Text()
        if len(line) == 0 {
            continue
        }

        // Trouve le premier espace sans Split
        spaceIdx := strings.Index(line, " ")
        if spaceIdx == -1 {
            continue
        }

        key := strings.ToLower(strings.TrimSpace(line[:spaceIdx]))
        results[key]++
    }

    return results, scanner.Err()
}
```

## Outils pour mesurer les optimisations

### Benchmark comparatif

```go
func BenchmarkAnalyzeLogsSlow(b *testing.B) {
    for i := 0; i < b.N; i++ {
        _, err := analyzeLogsSlow("test.log")
        if err != nil {
            b.Fatal(err)
        }
    }
}

func BenchmarkAnalyzeLogsFast(b *testing.B) {
    for i := 0; i < b.N; i++ {
        _, err := analyzeLogsFast("test.log")
        if err != nil {
            b.Fatal(err)
        }
    }
}
```

### Mesurer les allocations

```go
func BenchmarkStringBuilding(b *testing.B) {
    b.Run("Slow", func(b *testing.B) {
        b.ReportAllocs() // Affiche les allocations
        for i := 0; i < b.N; i++ {
            buildURLSlow([]string{"api", "v1", "users", "123"})
        }
    })

    b.Run("Fast", func(b *testing.B) {
        b.ReportAllocs()
        for i := 0; i < b.N; i++ {
            buildURLFast([]string{"api", "v1", "users", "123"})
        }
    })
}
```

## Checklist d'optimisation

### Avant d'optimiser
- [ ] Profiler le code pour identifier les vrais goulots d'√©tranglement
- [ ] Mesurer les performances actuelles
- [ ] D√©finir des objectifs clairs

### Pendant l'optimisation
- [ ] Optimiser une chose √† la fois
- [ ] Mesurer l'impact de chaque changement
- [ ] Conserver la lisibilit√© du code

### Apr√®s l'optimisation
- [ ] Valider que les optimisations fonctionnent
- [ ] Tester que le comportement reste correct
- [ ] Documenter les changements importants

## Pi√®ges √† √©viter

### 1. Optimisation pr√©matur√©e
```go
// ‚ùå Mauvais : Optimiser sans mesurer
func processData(data []string) {
    // Code compliqu√© "pour la performance"
    // mais le gain est n√©gligeable
}
```

### 2. Sacrifier la lisibilit√©
```go
// ‚ùå Mauvais : Code illisible pour un gain minimal
func calculate(a, b int) int {
    return ((a<<1)^b)&((b<<1)^a) // Qu'est-ce que √ßa fait ?
}

// ‚úÖ Bon : Code clair
func calculate(a, b int) int {
    return 2*a*b / (a + b) // Formule claire
}
```

### 3. Optimiser au mauvais endroit
Optimiser une fonction appel√©e une fois par heure n'aura pas d'impact sur les performances globales.

## Exercices pratiques

### Exercice 1 : Optimiser une recherche
```go
// Optimisez cette fonction
func findUsers(users []User, criteria SearchCriteria) []User {
    var results []User
    for _, user := range users {
        if matchesCriteria(user, criteria) {
            results = append(results, user)
        }
    }
    return results
}
```

### Exercice 2 : Optimiser un traitement de donn√©es
```go
// Optimisez cette fonction qui traite un CSV
func processCSV(filename string) error {
    file, err := os.Open(filename)
    if err != nil {
        return err
    }
    defer file.Close()

    reader := csv.NewReader(file)
    records, err := reader.ReadAll()
    if err != nil {
        return err
    }

    for _, record := range records {
        // Traitement ligne par ligne
        processRecord(record)
    }

    return nil
}
```

## R√©sum√©

Les optimisations courantes en Go suivent des patterns bien √©tablis :

1. **Algorithmes** : Choisir la bonne complexit√©
2. **Structures de donn√©es** : Utiliser les bonnes structures et pr√©-allouer
3. **M√©moire** : R√©utiliser les objets et √©viter les allocations
4. **I/O** : Utiliser le buffering et traiter par chunks
5. **Concurrence** : Worker pools et mutex appropri√©s

**R√®gle d'or** : Toujours mesurer avant et apr√®s vos optimisations !

Dans le prochain chapitre, nous verrons comment optimiser le garbage collector et comprendre son impact sur les performances.

‚è≠Ô∏è
