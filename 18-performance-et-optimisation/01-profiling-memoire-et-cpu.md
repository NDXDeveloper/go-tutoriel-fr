üîù Retour au [Sommaire](/SOMMAIRE.md)

# 18-1. Profiling m√©moire et CPU

## Introduction

Le profiling est l'art de mesurer les performances de votre programme pour identifier o√π il passe le plus de temps (profiling CPU) et o√π il utilise le plus de m√©moire (profiling m√©moire). C'est comme avoir une radiographie de votre application en fonctionnement !

En Go, les outils de profiling sont int√©gr√©s au langage et tr√®s faciles √† utiliser. Pas besoin d'outils externes compliqu√©s.

## Qu'est-ce que le profiling ?

Imaginez que vous voulez savoir pourquoi votre voiture consomme trop d'essence. Vous pourriez :
- Mesurer la consommation sur autoroute vs en ville
- V√©rifier si le moteur travaille plus dur dans certaines conditions
- Identifier les pi√®ces qui consomment le plus d'√©nergie

Le profiling fait la m√™me chose pour votre programme : il vous montre o√π votre code "consomme" le plus de ressources.

## Types de profiling en Go

### 1. Profiling CPU
- **Quoi** : Mesure o√π votre programme passe le plus de temps
- **Pourquoi** : Identifier les fonctions lentes
- **Quand** : Votre programme est lent √† s'ex√©cuter

### 2. Profiling m√©moire
- **Quoi** : Mesure quelles parties allouent le plus de m√©moire
- **Pourquoi** : R√©duire l'utilisation m√©moire et am√©liorer le GC
- **Quand** : Votre programme consomme trop de RAM

## M√©thodes de profiling

### M√©thode 1 : Profiling avec les tests (le plus simple)

C'est la m√©thode la plus facile pour d√©buter. Vous cr√©ez un test qui ex√©cute votre code et Go g√©n√®re automatiquement les profils.

#### Exemple pratique : Profiling d'une fonction de tri

```go
// main.go
package main

import (
    "math/rand"
    "sort"
    "time"
)

// Fonction simple qui trie des nombres
func sortNumbers(n int) []int {
    numbers := make([]int, n)
    for i := 0; i < n; i++ {
        numbers[i] = rand.Intn(1000)
    }
    sort.Ints(numbers)
    return numbers
}

// Fonction qui fait beaucoup d'allocations m√©moire
func createManyStrings(n int) []string {
    var result []string
    for i := 0; i < n; i++ {
        // Attention : cette fa√ßon est inefficace !
        result = append(result, "string number "+string(rune(i)))
    }
    return result
}

func main() {
    rand.Seed(time.Now().UnixNano())
    sortNumbers(100000)
    createManyStrings(10000)
}
```

```go
// main_test.go
package main

import (
    "testing"
)

func BenchmarkSortNumbers(b *testing.B) {
    for i := 0; i < b.N; i++ {
        sortNumbers(10000)
    }
}

func BenchmarkCreateManyStrings(b *testing.B) {
    for i := 0; i < b.N; i++ {
        createManyStrings(1000)
    }
}
```

#### G√©n√©rer les profils

```bash
# Profiling CPU
go test -bench=. -cpuprofile=cpu.prof

# Profiling m√©moire
go test -bench=. -memprofile=mem.prof

# Les deux √† la fois
go test -bench=. -cpuprofile=cpu.prof -memprofile=mem.prof
```

#### Analyser les r√©sultats

```bash
# Analyser le profil CPU
go tool pprof cpu.prof

# Analyser le profil m√©moire
go tool pprof mem.prof
```

### M√©thode 2 : Profiling dans une application web

Pour une application web, vous pouvez activer le profiling en ajoutant quelques lignes :

```go
package main

import (
    "fmt"
    "log"
    "net/http"
    _ "net/http/pprof" // Import pour activer le profiling
    "time"
)

func slowHandler(w http.ResponseWriter, r *http.Request) {
    // Simulation d'une op√©ration lente
    time.Sleep(100 * time.Millisecond)

    // Simulation d'allocations m√©moire
    data := make([]byte, 1024*1024) // 1MB
    for i := range data {
        data[i] = byte(i % 256)
    }

    fmt.Fprintf(w, "Hello, cette page a pris du temps √† charger!")
}

func main() {
    http.HandleFunc("/slow", slowHandler)

    fmt.Println("Serveur d√©marr√© sur :8080")
    fmt.Println("Profiling disponible sur :8080/debug/pprof/")
    log.Fatal(http.ListenAndServe(":8080", nil))
}
```

Avec cette configuration, vous pouvez :

```bash
# Voir les profils disponibles
curl http://localhost:8080/debug/pprof/

# G√©n√©rer un profil CPU de 30 secondes
go tool pprof http://localhost:8080/debug/pprof/profile?seconds=30

# G√©n√©rer un profil m√©moire
go tool pprof http://localhost:8080/debug/pprof/heap
```

## Utiliser pprof : Guide pas √† pas

### Interface en ligne de commande

Quand vous ex√©cutez `go tool pprof`, vous entrez dans un mode interactif :

```bash
$ go tool pprof cpu.prof
Type: cpu
Time: Dec 13, 2024 at 2:30pm (CET)
Duration: 2.05s, Total samples = 1.85s (90.24%)
Entering interactive mode (type "help" for commands, "o" for options)
(pprof)
```

#### Commandes essentielles

```bash
# Voir les 10 fonctions qui consomment le plus de CPU
(pprof) top10

# Voir les d√©tails d'une fonction sp√©cifique
(pprof) list main.sortNumbers

# Voir qui appelle une fonction
(pprof) peek sortNumbers

# G√©n√©rer un graphique (n√©cessite Graphviz)
(pprof) png > profile.png

# Voir l'aide
(pprof) help
```

### Interface web (plus visuelle)

```bash
# Lancer l'interface web
go tool pprof -http=:8081 cpu.prof
```

Ouvrez votre navigateur sur `http://localhost:8081` pour voir :
- **Graph** : Graphique des appels de fonctions
- **Top** : Liste des fonctions les plus co√ªteuses
- **Flame Graph** : Visualisation en flamme (tr√®s utile !)

## Interpr√©ter les r√©sultats

### Profiling CPU

```bash
(pprof) top10
Showing nodes accounting for 1.23s, 66.49% of 1.85s total
Dropped 15 nodes (< 0.09s)
      flat  flat%   sum%        cum   cum%
     0.45s 24.32% 24.32%      0.45s 24.32%  runtime.memclrNoHeapPointers
     0.23s 12.43% 36.76%      0.23s 12.43%  sort.insertionSort
     0.21s 11.35% 48.11%      0.65s 35.14%  sort.quickSort
     0.18s  9.73% 57.84%      0.18s  9.73%  runtime.mallocgc
     0.16s  8.65% 66.49%      0.16s  8.65%  math/rand.Intn
```

**Explication :**
- **flat** : Temps pass√© dans cette fonction uniquement
- **flat%** : Pourcentage du temps total
- **sum%** : Pourcentage cumul√©
- **cum** : Temps total incluant les fonctions appel√©es
- **cum%** : Pourcentage cumul√© incluant les sous-fonctions

### Profiling m√©moire

```bash
(pprof) top10
Showing nodes accounting for 512.19MB, 96.61% of 530.05MB total
Dropped 8 nodes (< 26.50MB)
      flat  flat%   sum%        cum   cum%
  256.06MB 48.31% 48.31%   256.06MB 48.31%  main.createManyStrings
  128.05MB 24.16% 72.47%   128.05MB 24.16%  main.sortNumbers
  128.08MB 24.14% 96.61%   128.08MB 24.14%  runtime.makeslice
```

**Explication :**
- **flat** : M√©moire allou√©e directement par cette fonction
- **cum** : M√©moire totale incluant les fonctions appel√©es

## Exemple complet : Optimiser une fonction lente

### Probl√®me : Fonction lente

```go
// Version lente
func processData(data []string) map[string]int {
    result := make(map[string]int)
    for _, item := range data {
        // Op√©ration co√ªteuse : conversion r√©p√©t√©e
        key := strings.ToLower(strings.TrimSpace(item))
        result[key]++
    }
    return result
}
```

### √âtape 1 : Mesurer

```go
func BenchmarkProcessData(b *testing.B) {
    data := make([]string, 1000)
    for i := range data {
        data[i] = fmt.Sprintf("  Item %d  ", i%100)
    }

    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        processData(data)
    }
}
```

```bash
go test -bench=BenchmarkProcessData -cpuprofile=cpu.prof
```

### √âtape 2 : Analyser

```bash
go tool pprof cpu.prof
(pprof) top10
```

Vous verrez probablement que `strings.ToLower` et `strings.TrimSpace` consomment beaucoup de CPU.

### √âtape 3 : Optimiser

```go
// Version optimis√©e
func processDataOptimized(data []string) map[string]int {
    result := make(map[string]int, len(data)/2) // Pr√©-allouer

    for _, item := range data {
        // √âviter les allocations r√©p√©t√©es
        key := strings.ToLower(strings.TrimSpace(item))
        result[key]++
    }
    return result
}
```

### √âtape 4 : V√©rifier l'am√©lioration

```bash
go test -bench=. -cpuprofile=cpu_optimized.prof
```

## Profiling m√©moire : Cas pratiques

### D√©tecter les fuites m√©moire

```go
func memoryLeakExample() {
    // Simulation d'une fuite m√©moire
    var leakySlice [][]byte

    for i := 0; i < 1000; i++ {
        // Chaque it√©ration ajoute 1MB qui ne sera jamais lib√©r√©
        data := make([]byte, 1024*1024)
        leakySlice = append(leakySlice, data)
    }

    // La slice leakySlice garde des r√©f√©rences, emp√™chant le GC
    // de lib√©rer la m√©moire
}
```

### Optimiser les allocations

```go
// Version qui alloue beaucoup
func inefficientStringBuilder(n int) string {
    var result string
    for i := 0; i < n; i++ {
        result += fmt.Sprintf("item-%d,", i) // Allocation √† chaque it√©ration !
    }
    return result
}

// Version optimis√©e
func efficientStringBuilder(n int) string {
    var builder strings.Builder
    builder.Grow(n * 10) // Pr√©-allouer la capacit√©

    for i := 0; i < n; i++ {
        builder.WriteString(fmt.Sprintf("item-%d,", i))
    }
    return builder.String()
}
```

## Outils compl√©mentaires

### go tool trace

Pour analyser les goroutines et la concurrence :

```go
func BenchmarkConcurrentWork(b *testing.B) {
    for i := 0; i < b.N; i++ {
        concurrentWork()
    }
}
```

```bash
go test -bench=BenchmarkConcurrentWork -trace=trace.out
go tool trace trace.out
```

### Benchstat

Pour comparer les performances avant/apr√®s optimisation :

```bash
# G√©n√©rer les benchmarks avant optimisation
go test -bench=. -count=10 > before.txt

# Apr√®s optimisation
go test -bench=. -count=10 > after.txt

# Comparer
go install golang.org/x/perf/cmd/benchstat@latest
benchstat before.txt after.txt
```

## Bonnes pratiques

### 1. Profiler r√©guli√®rement
- Int√©grez le profiling dans votre workflow de d√©veloppement
- Mesurez avant et apr√®s chaque optimisation

### 2. Profiler en conditions r√©elles
- Utilisez des donn√©es similaires √† la production
- Testez avec la charge r√©elle

### 3. Ne pas sur-optimiser
- Concentrez-vous sur les vrais goulots d'√©tranglement
- 80% des probl√®mes viennent souvent de 20% du code

### 4. Garder les profils
- Conservez les profils pour comparer les √©volutions
- Documentez vos optimisations

## Exercices pratiques

### Exercice 1 : Profiler une fonction simple

```go
func fibonacci(n int) int {
    if n <= 1 {
        return n
    }
    return fibonacci(n-1) + fibonacci(n-2)
}
```

**√Ä faire :**
1. Cr√©er un benchmark pour cette fonction
2. G√©n√©rer un profil CPU
3. Identifier pourquoi elle est lente
4. Proposer une version optimis√©e

### Exercice 2 : Analyser les allocations m√©moire

```go
func processSlice(data []int) []int {
    var result []int
    for _, v := range data {
        if v%2 == 0 {
            result = append(result, v*2)
        }
    }
    return result
}
```

**√Ä faire :**
1. Cr√©er un benchmark avec un grand slice
2. G√©n√©rer un profil m√©moire
3. Compter les allocations
4. Optimiser pour r√©duire les allocations

## R√©sum√©

Le profiling est essentiel pour :
- **Identifier** les vrais probl√®mes de performance
- **Mesurer** l'impact des optimisations
- **Comprendre** le comportement de votre application

**Outils cl√©s :**
- `go test -cpuprofile` et `-memprofile`
- `go tool pprof` avec interface CLI et web
- `net/http/pprof` pour les applications web

**M√©thodologie :**
1. Mesurer d'abord
2. Identifier les goulots d'√©tranglement
3. Optimiser de mani√®re cibl√©e
4. Valider l'am√©lioration

Dans le prochain chapitre, nous verrons les optimisations courantes que vous pouvez appliquer une fois que vous avez identifi√© les probl√®mes avec le profiling.

‚è≠Ô∏è
